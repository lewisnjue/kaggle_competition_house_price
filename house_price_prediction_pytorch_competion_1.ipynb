{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEOasJsiiBOjbjWfTNVkrL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lewisnjue/kaggle_competition_house_price/blob/main/house_price_prediction_pytorch_competion_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "YpW_atngS2uH",
        "outputId": "2645221a-6f04-4707-e82f-dd0bc4df19a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bdb54c87-115e-418b-9a35-366b92712868\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bdb54c87-115e-418b-9a35-366b92712868\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# let me upload my kaggle api key programatically\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# this is the programmatically way to putting your api keys to google colab use it in your code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "''' for many casses teh kaggle is aready installed  '''\n",
        "# this will install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "Bbdp2tPhS-rG",
        "outputId": "232f2f17-1c50-4834-91dc-ae9fd49558ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' for many casses teh kaggle is aready installed  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# i have also changed the permission of the file for me to read and write but others have no permission to it"
      ],
      "metadata": {
        "id": "2PG6K0eTUF6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the zip file now\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LetnCO3BUc28",
        "outputId": "eb097fea-28a2-4f2c-d0bc-830a02a16fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "house-prices-advanced-regression-techniques.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the file like this\n",
        "!unzip house-prices-advanced-regression-techniques.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDitu3-HUpLc",
        "outputId": "100bbd8c-03c7-403c-ac45-9e58342da64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  house-prices-advanced-regression-techniques.zip\n",
            "replace data_description.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-gftRvIVVj0",
        "outputId": "39cc97d3-a05b-4211-f4c9-f77c86bcc34b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_description.txt\t\t\t\t sample_data\t\ttest.csv\n",
            "house-prices-advanced-regression-techniques.zip  sample_submission.csv\ttrain.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe for my train data import the libraries am going to use\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('train.csv',index_col='Id')\n"
      ],
      "metadata": {
        "id": "s-n4ZU9xVW_j"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "wm5p4V4YWZDG",
        "outputId": "0e65a258-9172-437d-bc07-c3e521778479"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "Id                                                                    \n",
              "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "4           70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "   LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
              "Id                                  ...                                     \n",
              "1          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
              "2          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
              "3          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
              "4          Lvl    AllPub    Corner  ...        0    NaN   NaN         NaN   \n",
              "5          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
              "\n",
              "   MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "Id                                                             \n",
              "1        0      2    2008        WD         Normal     208500  \n",
              "2        0      5    2007        WD         Normal     181500  \n",
              "3        0      9    2008        WD         Normal     223500  \n",
              "4        0      2    2006        WD        Abnorml     140000  \n",
              "5        0     12    2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d393f12-90aa-4ec4-bcf8-85c715a2a92b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 80 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d393f12-90aa-4ec4-bcf8-85c715a2a92b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d393f12-90aa-4ec4-bcf8-85c715a2a92b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d393f12-90aa-4ec4-bcf8-85c715a2a92b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-72157b32-af1b-4c64-89d9-8013196669b8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72157b32-af1b-4c64-89d9-8013196669b8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-72157b32-af1b-4c64-89d9-8013196669b8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJM5uGb-WdgE",
        "outputId": "ebbe2180-f00a-4465-b8c1-c10860d28e68"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df.isna()).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "yBEJfemdXAl0",
        "outputId": "7dbb41b4-c517-48c0-c4eb-7801b23aad31"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MSSubClass         0\n",
              "MSZoning           0\n",
              "LotFrontage      259\n",
              "LotArea            0\n",
              "Street             0\n",
              "                ... \n",
              "MoSold             0\n",
              "YrSold             0\n",
              "SaleType           0\n",
              "SaleCondition      0\n",
              "SalePrice          0\n",
              "Length: 80, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MSSubClass</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSZoning</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotArea</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Street</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MoSold</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YrSold</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SaleType</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SaleCondition</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "B4fu2kvPXPx0",
        "outputId": "2bba67a4-6ee9-4d6e-e865-4f0f3faef4f6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
              "count  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000   \n",
              "mean     56.897260    70.049958   10516.828082     6.099315     5.575342   \n",
              "std      42.300571    24.284752    9981.264932     1.382997     1.112799   \n",
              "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
              "25%      20.000000    59.000000    7553.500000     5.000000     5.000000   \n",
              "50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n",
              "75%      70.000000    80.000000   11601.500000     7.000000     6.000000   \n",
              "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
              "\n",
              "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\n",
              "count  1460.000000   1460.000000  1452.000000  1460.000000  1460.000000  ...   \n",
              "mean   1971.267808   1984.865753   103.685262   443.639726    46.549315  ...   \n",
              "std      30.202904     20.645407   181.066207   456.098091   161.319273  ...   \n",
              "min    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%    1954.000000   1967.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%    1973.000000   1994.000000     0.000000   383.500000     0.000000  ...   \n",
              "75%    2000.000000   2004.000000   166.000000   712.250000     0.000000  ...   \n",
              "max    2010.000000   2010.000000  1600.000000  5644.000000  1474.000000  ...   \n",
              "\n",
              "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
              "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
              "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
              "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
              "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
              "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
              "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
              "\n",
              "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
              "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
              "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
              "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
              "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
              "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
              "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
              "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
              "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
              "\n",
              "[8 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10b6dbe9-ce3c-4e81-8a20-c86efe173c34\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>46.549315</td>\n",
              "      <td>...</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>161.319273</td>\n",
              "      <td>...</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>1474.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10b6dbe9-ce3c-4e81-8a20-c86efe173c34')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10b6dbe9-ce3c-4e81-8a20-c86efe173c34 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10b6dbe9-ce3c-4e81-8a20-c86efe173c34');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b5de4b4-8f1b-4f84-838c-0ea7fbb2a3fe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b5de4b4-8f1b-4f84-838c-0ea7fbb2a3fe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b5de4b4-8f1b-4f84-838c-0ea7fbb2a3fe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' numerical_cols = df.select_dtypes(include=np.number).columns # this will get me the numerical columns\n",
        "for col in numerical_cols:\n",
        "    if df[col].isnull().any():\n",
        "        df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "# Categorical columns with null values dropped\n",
        "categorical_cols = df.select_dtypes(exclude=np.number).columns\n",
        "for col in categorical_cols:\n",
        "    if df[col].isnull().any():\n",
        "        df.dropna(subset=[col], inplace=True) '''\n",
        "\n",
        "numerical_columns = df.select_dtypes(include=np.number).columns\n",
        "categorical_columns = df.select_dtypes(exclude=np.number).columns\n",
        "list(numerical_columns),list(categorical_columns)\n",
        "df[list(numerical_columns)] = df[list(numerical_columns)].fillna(df[list(numerical_columns)].mean())\n",
        "df[list(categorical_columns)] = df[list(categorical_columns)].fillna('Missing')\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "SwQoBgLHYc2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "9f80a9e9-ab48-4271-d79d-4c5d1f6e03a5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    MSSubClass MSZoning  LotFrontage  LotArea Street    Alley LotShape  \\\n",
              "Id                                                                       \n",
              "1           60       RL         65.0     8450   Pave  Missing      Reg   \n",
              "2           20       RL         80.0     9600   Pave  Missing      Reg   \n",
              "3           60       RL         68.0    11250   Pave  Missing      IR1   \n",
              "4           70       RL         60.0     9550   Pave  Missing      IR1   \n",
              "5           60       RL         84.0    14260   Pave  Missing      IR1   \n",
              "\n",
              "   LandContour Utilities LotConfig  ... PoolArea   PoolQC    Fence  \\\n",
              "Id                                  ...                              \n",
              "1          Lvl    AllPub    Inside  ...        0  Missing  Missing   \n",
              "2          Lvl    AllPub       FR2  ...        0  Missing  Missing   \n",
              "3          Lvl    AllPub    Inside  ...        0  Missing  Missing   \n",
              "4          Lvl    AllPub    Corner  ...        0  Missing  Missing   \n",
              "5          Lvl    AllPub       FR2  ...        0  Missing  Missing   \n",
              "\n",
              "   MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "Id                                                                         \n",
              "1      Missing       0      2    2008        WD         Normal     208500  \n",
              "2      Missing       0      5    2007        WD         Normal     181500  \n",
              "3      Missing       0      9    2008        WD         Normal     223500  \n",
              "4      Missing       0      2    2006        WD        Abnorml     140000  \n",
              "5      Missing       0     12    2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8a82126-75c4-486e-b961-b3a2ff85bff0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 80 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8a82126-75c4-486e-b961-b3a2ff85bff0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8a82126-75c4-486e-b961-b3a2ff85bff0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8a82126-75c4-486e-b961-b3a2ff85bff0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89bcb4a4-53e8-4b1b-8230-9a48f4fc9903\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89bcb4a4-53e8-4b1b-8230-9a48f4fc9903')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89bcb4a4-53e8-4b1b-8230-9a48f4fc9903 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select_dtypes(include=np.number).columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Afn807ZCNk",
        "outputId": "7d1ed311-7036-4331-dadc-e6804014e5f2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
              "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
              "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
              "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
              "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
              "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
              "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
              "       'MoSold', 'YrSold', 'SalePrice'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select_dtypes(exclude=np.number).columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C01IpU6xZFWY",
        "outputId": "6c50833f-e422-44c3-e2b3-5f1ae6124cf4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
              "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
              "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
              "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
              "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
              "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
              "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
              "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
              "       'SaleType', 'SaleCondition'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['SalePrice'].isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOJMNAbGZKMn",
        "outputId": "9ec81d91-d97b-4ade-a3ab-7acdd632205f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "749iC-PHZrYl",
        "outputId": "f02383e7-d53a-414e-eef4-4fc890d80287"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MSSubClass       0\n",
              "MSZoning         0\n",
              "LotFrontage      0\n",
              "LotArea          0\n",
              "Street           0\n",
              "                ..\n",
              "MoSold           0\n",
              "YrSold           0\n",
              "SaleType         0\n",
              "SaleCondition    0\n",
              "SalePrice        0\n",
              "Length: 80, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MSSubClass</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSZoning</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotArea</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Street</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MoSold</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YrSold</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SaleType</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SaleCondition</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now in my data i have no null values -> this is very good now for my data predictions\n",
        "''' let me now separate the target columns form the train columns '''\n",
        "target = df['SalePrice']\n",
        "labels = df.drop('SalePrice',axis=1)"
      ],
      "metadata": {
        "id": "w2S1wMX6aPEW"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target.shape,labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2jhtsG2ajxk",
        "outputId": "69f42fb4-3102-477a-d571-54c646ce3ec0"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1460,), (1460, 79))"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' let me normilize my data '''\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "numerical_cols_no_target = list(numerical_columns)[:-1]\n",
        "labels[numerical_cols_no_target] = scaler.fit_transform(labels[numerical_cols_no_target])\n",
        "labels.head()"
      ],
      "metadata": {
        "id": "eusId38JalPC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "59b286ff-34f0-4b3a-d937-593d2f54b471"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    MSSubClass MSZoning  LotFrontage   LotArea Street    Alley LotShape  \\\n",
              "Id                                                                        \n",
              "1     0.073375       RL    -0.229372 -0.207142   Pave  Missing      Reg   \n",
              "2    -0.872563       RL     0.451936 -0.091886   Pave  Missing      Reg   \n",
              "3     0.073375       RL    -0.093110  0.073480   Pave  Missing      IR1   \n",
              "4     0.309859       RL    -0.456474 -0.096897   Pave  Missing      IR1   \n",
              "5     0.073375       RL     0.633618  0.375148   Pave  Missing      IR1   \n",
              "\n",
              "   LandContour Utilities LotConfig  ... ScreenPorch  PoolArea   PoolQC  \\\n",
              "Id                                  ...                                  \n",
              "1          Lvl    AllPub    Inside  ...   -0.270208 -0.068692  Missing   \n",
              "2          Lvl    AllPub       FR2  ...   -0.270208 -0.068692  Missing   \n",
              "3          Lvl    AllPub    Inside  ...   -0.270208 -0.068692  Missing   \n",
              "4          Lvl    AllPub    Corner  ...   -0.270208 -0.068692  Missing   \n",
              "5          Lvl    AllPub       FR2  ...   -0.270208 -0.068692  Missing   \n",
              "\n",
              "      Fence MiscFeature   MiscVal    MoSold    YrSold  SaleType  SaleCondition  \n",
              "Id                                                                              \n",
              "1   Missing     Missing -0.087688 -1.599111  0.138777        WD         Normal  \n",
              "2   Missing     Missing -0.087688 -0.489110 -0.614439        WD         Normal  \n",
              "3   Missing     Missing -0.087688  0.990891  0.138777        WD         Normal  \n",
              "4   Missing     Missing -0.087688 -1.599111 -1.367655        WD        Abnorml  \n",
              "5   Missing     Missing -0.087688  2.100892  0.138777        WD         Normal  \n",
              "\n",
              "[5 rows x 79 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35e51058-59a2-4160-8052-270c24c4dfb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.073375</td>\n",
              "      <td>RL</td>\n",
              "      <td>-0.229372</td>\n",
              "      <td>-0.207142</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.270208</td>\n",
              "      <td>-0.068692</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>-0.087688</td>\n",
              "      <td>-1.599111</td>\n",
              "      <td>0.138777</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.872563</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.451936</td>\n",
              "      <td>-0.091886</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.270208</td>\n",
              "      <td>-0.068692</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>-0.087688</td>\n",
              "      <td>-0.489110</td>\n",
              "      <td>-0.614439</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.073375</td>\n",
              "      <td>RL</td>\n",
              "      <td>-0.093110</td>\n",
              "      <td>0.073480</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.270208</td>\n",
              "      <td>-0.068692</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>-0.087688</td>\n",
              "      <td>0.990891</td>\n",
              "      <td>0.138777</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.309859</td>\n",
              "      <td>RL</td>\n",
              "      <td>-0.456474</td>\n",
              "      <td>-0.096897</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.270208</td>\n",
              "      <td>-0.068692</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>-0.087688</td>\n",
              "      <td>-1.599111</td>\n",
              "      <td>-1.367655</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.073375</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.633618</td>\n",
              "      <td>0.375148</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Missing</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.270208</td>\n",
              "      <td>-0.068692</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Missing</td>\n",
              "      <td>-0.087688</td>\n",
              "      <td>2.100892</td>\n",
              "      <td>0.138777</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 79 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35e51058-59a2-4160-8052-270c24c4dfb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35e51058-59a2-4160-8052-270c24c4dfb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35e51058-59a2-4160-8052-270c24c4dfb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-624113b9-f29e-4bb3-880d-ef4e92fefcd4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-624113b9-f29e-4bb3-880d-ef4e92fefcd4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-624113b9-f29e-4bb3-880d-ef4e92fefcd4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''  do one hot encoding  for our categorical columns '''\n",
        "labels = pd.get_dummies(labels,drop_first=True,dtype=int)\n",
        "labels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "QYQaSJMzbr_N",
        "outputId": "61acbbe5-7ddd-4b4d-bec5-057c54399da1"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "Id                                                                           \n",
              "1     0.073375    -0.229372 -0.207142     0.651479    -0.517200   1.050994   \n",
              "2    -0.872563     0.451936 -0.091886    -0.071836     2.179628   0.156734   \n",
              "3     0.073375    -0.093110  0.073480     0.651479    -0.517200   0.984752   \n",
              "4     0.309859    -0.456474 -0.096897     0.651479    -0.517200  -1.863632   \n",
              "5     0.073375     0.633618  0.375148     1.374795    -0.517200   0.951632   \n",
              "\n",
              "    YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLI  \\\n",
              "Id                                                    ...                   \n",
              "1       0.878668    0.511418    0.575425   -0.288653  ...               0   \n",
              "2      -0.429577   -0.574410    1.171992   -0.288653  ...               0   \n",
              "3       0.830215    0.323060    0.092907   -0.288653  ...               0   \n",
              "4      -0.720298   -0.574410   -0.499274   -0.288653  ...               0   \n",
              "5       0.733308    1.364570    0.463568   -0.288653  ...               0   \n",
              "\n",
              "    SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
              "Id                                                            \n",
              "1                0             0             0            1   \n",
              "2                0             0             0            1   \n",
              "3                0             0             0            1   \n",
              "4                0             0             0            1   \n",
              "5                0             0             0            1   \n",
              "\n",
              "    SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
              "Id                                                                      \n",
              "1                       0                     0                     0   \n",
              "2                       0                     0                     0   \n",
              "3                       0                     0                     0   \n",
              "4                       0                     0                     0   \n",
              "5                       0                     0                     0   \n",
              "\n",
              "    SaleCondition_Normal  SaleCondition_Partial  \n",
              "Id                                               \n",
              "1                      1                      0  \n",
              "2                      1                      0  \n",
              "3                      1                      0  \n",
              "4                      0                      0  \n",
              "5                      1                      0  \n",
              "\n",
              "[5 rows x 260 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-063723a2-84ed-484d-b53d-fb595a5dbfc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType_ConLI</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.073375</td>\n",
              "      <td>-0.229372</td>\n",
              "      <td>-0.207142</td>\n",
              "      <td>0.651479</td>\n",
              "      <td>-0.517200</td>\n",
              "      <td>1.050994</td>\n",
              "      <td>0.878668</td>\n",
              "      <td>0.511418</td>\n",
              "      <td>0.575425</td>\n",
              "      <td>-0.288653</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.872563</td>\n",
              "      <td>0.451936</td>\n",
              "      <td>-0.091886</td>\n",
              "      <td>-0.071836</td>\n",
              "      <td>2.179628</td>\n",
              "      <td>0.156734</td>\n",
              "      <td>-0.429577</td>\n",
              "      <td>-0.574410</td>\n",
              "      <td>1.171992</td>\n",
              "      <td>-0.288653</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.073375</td>\n",
              "      <td>-0.093110</td>\n",
              "      <td>0.073480</td>\n",
              "      <td>0.651479</td>\n",
              "      <td>-0.517200</td>\n",
              "      <td>0.984752</td>\n",
              "      <td>0.830215</td>\n",
              "      <td>0.323060</td>\n",
              "      <td>0.092907</td>\n",
              "      <td>-0.288653</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.309859</td>\n",
              "      <td>-0.456474</td>\n",
              "      <td>-0.096897</td>\n",
              "      <td>0.651479</td>\n",
              "      <td>-0.517200</td>\n",
              "      <td>-1.863632</td>\n",
              "      <td>-0.720298</td>\n",
              "      <td>-0.574410</td>\n",
              "      <td>-0.499274</td>\n",
              "      <td>-0.288653</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.073375</td>\n",
              "      <td>0.633618</td>\n",
              "      <td>0.375148</td>\n",
              "      <td>1.374795</td>\n",
              "      <td>-0.517200</td>\n",
              "      <td>0.951632</td>\n",
              "      <td>0.733308</td>\n",
              "      <td>1.364570</td>\n",
              "      <td>0.463568</td>\n",
              "      <td>-0.288653</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 260 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-063723a2-84ed-484d-b53d-fb595a5dbfc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-063723a2-84ed-484d-b53d-fb595a5dbfc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-063723a2-84ed-484d-b53d-fb595a5dbfc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f2191df9-919c-4b93-9ef1-af69033aa79d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2191df9-919c-4b93-9ef1-af69033aa79d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f2191df9-919c-4b93-9ef1-af69033aa79d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''  now convert my labels to tensor excluding the id column using pytorch '''\n",
        "labels = torch.from_numpy(labels.values).float()\n",
        "target = torch.from_numpy(target.values).float()"
      ],
      "metadata": {
        "id": "UQ_3jNoUb6eQ"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY6o_SJ7cA2U",
        "outputId": "c6247620-4434-47c0-c86b-36e9625cc0d6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0734, -0.2294, -0.2071,  ...,  0.0000,  1.0000,  0.0000],\n",
              "        [-0.8726,  0.4519, -0.0919,  ...,  0.0000,  1.0000,  0.0000],\n",
              "        [ 0.0734, -0.0931,  0.0735,  ...,  0.0000,  1.0000,  0.0000],\n",
              "        ...,\n",
              "        [ 0.3099, -0.1840, -0.1478,  ...,  0.0000,  1.0000,  0.0000],\n",
              "        [-0.8726, -0.0931, -0.0802,  ...,  0.0000,  1.0000,  0.0000],\n",
              "        [-0.8726,  0.2248, -0.0581,  ...,  0.0000,  1.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vU_gQ0bcPcg",
        "outputId": "2f711213-2272-4ed2-9ea5-745bf9d8b249"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1460, 260])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.dtype"
      ],
      "metadata": {
        "id": "WVbpYZOmdZzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca270e1b-af55-484b-8333-e4cf339f8b52"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxZcJ2fPmhtg",
        "outputId": "eba4f53f-0b6d-4abe-859e-220f2dcd32bd"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1460])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' create a model  '''\n",
        "class regression_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_features=260, out_features=200),  # Adjusted from 331 to 260\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=200, out_features=100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=100, out_features=50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=50, out_features=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "U_BdufF8mjiL"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' create a loss function and an optimzer '''\n",
        "model = regression_model()\n",
        "loss_fun = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "oG3GEDoSn62i"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' do some dummy prediction '''\n",
        "y_pred = model(labels.float())\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D67sHN1DoJ6s",
        "outputId": "87a47366-d1f4-4b12-8af8-680be5fafbd9"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1079],\n",
              "        [0.1027],\n",
              "        [0.1073],\n",
              "        ...,\n",
              "        [0.1111],\n",
              "        [0.1006],\n",
              "        [0.0926]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let now train our model\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    y_pred = model(labels.float())\n",
        "    loss = loss_fun(y_pred,target.float())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        y_pred = model(labels.float())\n",
        "        test_loss = loss_fun(y_pred,target.float())\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss} | Test Loss: {test_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYmG8dbWohXP",
        "outputId": "089dcc97-69cd-405f-a562-514b4d295759"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1460])) that is different to the input size (torch.Size([1460, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 39039229952.0 | Test Loss: 39039205376.0\n",
            "Epoch: 1 | Loss: 39039205376.0 | Test Loss: 39039188992.0\n",
            "Epoch: 2 | Loss: 39039188992.0 | Test Loss: 39039172608.0\n",
            "Epoch: 3 | Loss: 39039172608.0 | Test Loss: 39039148032.0\n",
            "Epoch: 4 | Loss: 39039148032.0 | Test Loss: 39039119360.0\n",
            "Epoch: 5 | Loss: 39039119360.0 | Test Loss: 39039090688.0\n",
            "Epoch: 6 | Loss: 39039090688.0 | Test Loss: 39039053824.0\n",
            "Epoch: 7 | Loss: 39039053824.0 | Test Loss: 39039004672.0\n",
            "Epoch: 8 | Loss: 39039004672.0 | Test Loss: 39038947328.0\n",
            "Epoch: 9 | Loss: 39038947328.0 | Test Loss: 39038873600.0\n",
            "Epoch: 10 | Loss: 39038873600.0 | Test Loss: 39038787584.0\n",
            "Epoch: 11 | Loss: 39038787584.0 | Test Loss: 39038681088.0\n",
            "Epoch: 12 | Loss: 39038681088.0 | Test Loss: 39038562304.0\n",
            "Epoch: 13 | Loss: 39038562304.0 | Test Loss: 39038414848.0\n",
            "Epoch: 14 | Loss: 39038414848.0 | Test Loss: 39038238720.0\n",
            "Epoch: 15 | Loss: 39038238720.0 | Test Loss: 39038038016.0\n",
            "Epoch: 16 | Loss: 39038038016.0 | Test Loss: 39037804544.0\n",
            "Epoch: 17 | Loss: 39037804544.0 | Test Loss: 39037530112.0\n",
            "Epoch: 18 | Loss: 39037530112.0 | Test Loss: 39037214720.0\n",
            "Epoch: 19 | Loss: 39037214720.0 | Test Loss: 39036850176.0\n",
            "Epoch: 20 | Loss: 39036850176.0 | Test Loss: 39036432384.0\n",
            "Epoch: 21 | Loss: 39036432384.0 | Test Loss: 39035953152.0\n",
            "Epoch: 22 | Loss: 39035953152.0 | Test Loss: 39035404288.0\n",
            "Epoch: 23 | Loss: 39035404288.0 | Test Loss: 39034781696.0\n",
            "Epoch: 24 | Loss: 39034781696.0 | Test Loss: 39034073088.0\n",
            "Epoch: 25 | Loss: 39034073088.0 | Test Loss: 39033274368.0\n",
            "Epoch: 26 | Loss: 39033274368.0 | Test Loss: 39032369152.0\n",
            "Epoch: 27 | Loss: 39032369152.0 | Test Loss: 39031357440.0\n",
            "Epoch: 28 | Loss: 39031357440.0 | Test Loss: 39030210560.0\n",
            "Epoch: 29 | Loss: 39030210560.0 | Test Loss: 39028936704.0\n",
            "Epoch: 30 | Loss: 39028936704.0 | Test Loss: 39027503104.0\n",
            "Epoch: 31 | Loss: 39027503104.0 | Test Loss: 39025905664.0\n",
            "Epoch: 32 | Loss: 39025905664.0 | Test Loss: 39024132096.0\n",
            "Epoch: 33 | Loss: 39024132096.0 | Test Loss: 39022153728.0\n",
            "Epoch: 34 | Loss: 39022153728.0 | Test Loss: 39019962368.0\n",
            "Epoch: 35 | Loss: 39019962368.0 | Test Loss: 39017541632.0\n",
            "Epoch: 36 | Loss: 39017541632.0 | Test Loss: 39014866944.0\n",
            "Epoch: 37 | Loss: 39014866944.0 | Test Loss: 39011905536.0\n",
            "Epoch: 38 | Loss: 39011905536.0 | Test Loss: 39008661504.0\n",
            "Epoch: 39 | Loss: 39008661504.0 | Test Loss: 39005081600.0\n",
            "Epoch: 40 | Loss: 39005081600.0 | Test Loss: 39001157632.0\n",
            "Epoch: 41 | Loss: 39001157632.0 | Test Loss: 38996852736.0\n",
            "Epoch: 42 | Loss: 38996852736.0 | Test Loss: 38992146432.0\n",
            "Epoch: 43 | Loss: 38992146432.0 | Test Loss: 38987001856.0\n",
            "Epoch: 44 | Loss: 38987001856.0 | Test Loss: 38981398528.0\n",
            "Epoch: 45 | Loss: 38981398528.0 | Test Loss: 38975291392.0\n",
            "Epoch: 46 | Loss: 38975291392.0 | Test Loss: 38968647680.0\n",
            "Epoch: 47 | Loss: 38968647680.0 | Test Loss: 38961434624.0\n",
            "Epoch: 48 | Loss: 38961434624.0 | Test Loss: 38953607168.0\n",
            "Epoch: 49 | Loss: 38953607168.0 | Test Loss: 38945136640.0\n",
            "Epoch: 50 | Loss: 38945136640.0 | Test Loss: 38935961600.0\n",
            "Epoch: 51 | Loss: 38935961600.0 | Test Loss: 38926049280.0\n",
            "Epoch: 52 | Loss: 38926049280.0 | Test Loss: 38915350528.0\n",
            "Epoch: 53 | Loss: 38915350528.0 | Test Loss: 38903812096.0\n",
            "Epoch: 54 | Loss: 38903812096.0 | Test Loss: 38891393024.0\n",
            "Epoch: 55 | Loss: 38891393024.0 | Test Loss: 38878027776.0\n",
            "Epoch: 56 | Loss: 38878027776.0 | Test Loss: 38863675392.0\n",
            "Epoch: 57 | Loss: 38863675392.0 | Test Loss: 38848274432.0\n",
            "Epoch: 58 | Loss: 38848274432.0 | Test Loss: 38831751168.0\n",
            "Epoch: 59 | Loss: 38831751168.0 | Test Loss: 38814060544.0\n",
            "Epoch: 60 | Loss: 38814060544.0 | Test Loss: 38795137024.0\n",
            "Epoch: 61 | Loss: 38795137024.0 | Test Loss: 38774915072.0\n",
            "Epoch: 62 | Loss: 38774915072.0 | Test Loss: 38753316864.0\n",
            "Epoch: 63 | Loss: 38753316864.0 | Test Loss: 38730272768.0\n",
            "Epoch: 64 | Loss: 38730272768.0 | Test Loss: 38705721344.0\n",
            "Epoch: 65 | Loss: 38705721344.0 | Test Loss: 38679580672.0\n",
            "Epoch: 66 | Loss: 38679580672.0 | Test Loss: 38651772928.0\n",
            "Epoch: 67 | Loss: 38651772928.0 | Test Loss: 38622220288.0\n",
            "Epoch: 68 | Loss: 38622220288.0 | Test Loss: 38590836736.0\n",
            "Epoch: 69 | Loss: 38590836736.0 | Test Loss: 38557544448.0\n",
            "Epoch: 70 | Loss: 38557544448.0 | Test Loss: 38522249216.0\n",
            "Epoch: 71 | Loss: 38522249216.0 | Test Loss: 38484869120.0\n",
            "Epoch: 72 | Loss: 38484869120.0 | Test Loss: 38445301760.0\n",
            "Epoch: 73 | Loss: 38445301760.0 | Test Loss: 38403461120.0\n",
            "Epoch: 74 | Loss: 38403461120.0 | Test Loss: 38359248896.0\n",
            "Epoch: 75 | Loss: 38359248896.0 | Test Loss: 38312558592.0\n",
            "Epoch: 76 | Loss: 38312558592.0 | Test Loss: 38263308288.0\n",
            "Epoch: 77 | Loss: 38263308288.0 | Test Loss: 38211379200.0\n",
            "Epoch: 78 | Loss: 38211379200.0 | Test Loss: 38156668928.0\n",
            "Epoch: 79 | Loss: 38156668928.0 | Test Loss: 38099066880.0\n",
            "Epoch: 80 | Loss: 38099066880.0 | Test Loss: 38038474752.0\n",
            "Epoch: 81 | Loss: 38038474752.0 | Test Loss: 37974773760.0\n",
            "Epoch: 82 | Loss: 37974773760.0 | Test Loss: 37907849216.0\n",
            "Epoch: 83 | Loss: 37907849216.0 | Test Loss: 37837582336.0\n",
            "Epoch: 84 | Loss: 37837582336.0 | Test Loss: 37763862528.0\n",
            "Epoch: 85 | Loss: 37763862528.0 | Test Loss: 37686562816.0\n",
            "Epoch: 86 | Loss: 37686562816.0 | Test Loss: 37605564416.0\n",
            "Epoch: 87 | Loss: 37605564416.0 | Test Loss: 37520752640.0\n",
            "Epoch: 88 | Loss: 37520752640.0 | Test Loss: 37432000512.0\n",
            "Epoch: 89 | Loss: 37432000512.0 | Test Loss: 37339185152.0\n",
            "Epoch: 90 | Loss: 37339185152.0 | Test Loss: 37242171392.0\n",
            "Epoch: 91 | Loss: 37242171392.0 | Test Loss: 37140836352.0\n",
            "Epoch: 92 | Loss: 37140836352.0 | Test Loss: 37035053056.0\n",
            "Epoch: 93 | Loss: 37035053056.0 | Test Loss: 36924702720.0\n",
            "Epoch: 94 | Loss: 36924702720.0 | Test Loss: 36809637888.0\n",
            "Epoch: 95 | Loss: 36809637888.0 | Test Loss: 36689743872.0\n",
            "Epoch: 96 | Loss: 36689743872.0 | Test Loss: 36564889600.0\n",
            "Epoch: 97 | Loss: 36564889600.0 | Test Loss: 36434939904.0\n",
            "Epoch: 98 | Loss: 36434939904.0 | Test Loss: 36299763712.0\n",
            "Epoch: 99 | Loss: 36299763712.0 | Test Loss: 36159242240.0\n",
            "Epoch: 100 | Loss: 36159242240.0 | Test Loss: 36013236224.0\n",
            "Epoch: 101 | Loss: 36013236224.0 | Test Loss: 35861630976.0\n",
            "Epoch: 102 | Loss: 35861630976.0 | Test Loss: 35704287232.0\n",
            "Epoch: 103 | Loss: 35704287232.0 | Test Loss: 35541090304.0\n",
            "Epoch: 104 | Loss: 35541090304.0 | Test Loss: 35371921408.0\n",
            "Epoch: 105 | Loss: 35371921408.0 | Test Loss: 35196649472.0\n",
            "Epoch: 106 | Loss: 35196649472.0 | Test Loss: 35015159808.0\n",
            "Epoch: 107 | Loss: 35015159808.0 | Test Loss: 34827341824.0\n",
            "Epoch: 108 | Loss: 34827341824.0 | Test Loss: 34633072640.0\n",
            "Epoch: 109 | Loss: 34633072640.0 | Test Loss: 34432258048.0\n",
            "Epoch: 110 | Loss: 34432258048.0 | Test Loss: 34224779264.0\n",
            "Epoch: 111 | Loss: 34224779264.0 | Test Loss: 34010552320.0\n",
            "Epoch: 112 | Loss: 34010552320.0 | Test Loss: 33789466624.0\n",
            "Epoch: 113 | Loss: 33789466624.0 | Test Loss: 33561434112.0\n",
            "Epoch: 114 | Loss: 33561434112.0 | Test Loss: 33326374912.0\n",
            "Epoch: 115 | Loss: 33326374912.0 | Test Loss: 33084203008.0\n",
            "Epoch: 116 | Loss: 33084203008.0 | Test Loss: 32834844672.0\n",
            "Epoch: 117 | Loss: 32834844672.0 | Test Loss: 32578240512.0\n",
            "Epoch: 118 | Loss: 32578240512.0 | Test Loss: 32314324992.0\n",
            "Epoch: 119 | Loss: 32314324992.0 | Test Loss: 32043053056.0\n",
            "Epoch: 120 | Loss: 32043053056.0 | Test Loss: 31764375552.0\n",
            "Epoch: 121 | Loss: 31764375552.0 | Test Loss: 31478263808.0\n",
            "Epoch: 122 | Loss: 31478263808.0 | Test Loss: 31184689152.0\n",
            "Epoch: 123 | Loss: 31184689152.0 | Test Loss: 30883639296.0\n",
            "Epoch: 124 | Loss: 30883639296.0 | Test Loss: 30575110144.0\n",
            "Epoch: 125 | Loss: 30575110144.0 | Test Loss: 30259109888.0\n",
            "Epoch: 126 | Loss: 30259109888.0 | Test Loss: 29935654912.0\n",
            "Epoch: 127 | Loss: 29935654912.0 | Test Loss: 29604775936.0\n",
            "Epoch: 128 | Loss: 29604775936.0 | Test Loss: 29266524160.0\n",
            "Epoch: 129 | Loss: 29266524160.0 | Test Loss: 28920946688.0\n",
            "Epoch: 130 | Loss: 28920946688.0 | Test Loss: 28568127488.0\n",
            "Epoch: 131 | Loss: 28568127488.0 | Test Loss: 28208144384.0\n",
            "Epoch: 132 | Loss: 28208144384.0 | Test Loss: 27841105920.0\n",
            "Epoch: 133 | Loss: 27841105920.0 | Test Loss: 27467122688.0\n",
            "Epoch: 134 | Loss: 27467122688.0 | Test Loss: 27086329856.0\n",
            "Epoch: 135 | Loss: 27086329856.0 | Test Loss: 26698885120.0\n",
            "Epoch: 136 | Loss: 26698885120.0 | Test Loss: 26304954368.0\n",
            "Epoch: 137 | Loss: 26304954368.0 | Test Loss: 25904726016.0\n",
            "Epoch: 138 | Loss: 25904726016.0 | Test Loss: 25498404864.0\n",
            "Epoch: 139 | Loss: 25498404864.0 | Test Loss: 25086214144.0\n",
            "Epoch: 140 | Loss: 25086214144.0 | Test Loss: 24668405760.0\n",
            "Epoch: 141 | Loss: 24668405760.0 | Test Loss: 24245245952.0\n",
            "Epoch: 142 | Loss: 24245245952.0 | Test Loss: 23817011200.0\n",
            "Epoch: 143 | Loss: 23817011200.0 | Test Loss: 23384016896.0\n",
            "Epoch: 144 | Loss: 23384016896.0 | Test Loss: 22946588672.0\n",
            "Epoch: 145 | Loss: 22946588672.0 | Test Loss: 22505076736.0\n",
            "Epoch: 146 | Loss: 22505076736.0 | Test Loss: 22059857920.0\n",
            "Epoch: 147 | Loss: 22059857920.0 | Test Loss: 21611319296.0\n",
            "Epoch: 148 | Loss: 21611319296.0 | Test Loss: 21159882752.0\n",
            "Epoch: 149 | Loss: 21159882752.0 | Test Loss: 20705982464.0\n",
            "Epoch: 150 | Loss: 20705982464.0 | Test Loss: 20250077184.0\n",
            "Epoch: 151 | Loss: 20250077184.0 | Test Loss: 19792650240.0\n",
            "Epoch: 152 | Loss: 19792650240.0 | Test Loss: 19334205440.0\n",
            "Epoch: 153 | Loss: 19334205440.0 | Test Loss: 18875262976.0\n",
            "Epoch: 154 | Loss: 18875262976.0 | Test Loss: 18416367616.0\n",
            "Epoch: 155 | Loss: 18416367616.0 | Test Loss: 17958080512.0\n",
            "Epoch: 156 | Loss: 17958080512.0 | Test Loss: 17500977152.0\n",
            "Epoch: 157 | Loss: 17500977152.0 | Test Loss: 17045664768.0\n",
            "Epoch: 158 | Loss: 17045664768.0 | Test Loss: 16592750592.0\n",
            "Epoch: 159 | Loss: 16592750592.0 | Test Loss: 16142863360.0\n",
            "Epoch: 160 | Loss: 16142863360.0 | Test Loss: 15696645120.0\n",
            "Epoch: 161 | Loss: 15696645120.0 | Test Loss: 15254743040.0\n",
            "Epoch: 162 | Loss: 15254743040.0 | Test Loss: 14817824768.0\n",
            "Epoch: 163 | Loss: 14817824768.0 | Test Loss: 14386554880.0\n",
            "Epoch: 164 | Loss: 14386554880.0 | Test Loss: 13961597952.0\n",
            "Epoch: 165 | Loss: 13961597952.0 | Test Loss: 13543631872.0\n",
            "Epoch: 166 | Loss: 13543631872.0 | Test Loss: 13133322240.0\n",
            "Epoch: 167 | Loss: 13133322240.0 | Test Loss: 12731332608.0\n",
            "Epoch: 168 | Loss: 12731332608.0 | Test Loss: 12338320384.0\n",
            "Epoch: 169 | Loss: 12338320384.0 | Test Loss: 11954921472.0\n",
            "Epoch: 170 | Loss: 11954921472.0 | Test Loss: 11581761536.0\n",
            "Epoch: 171 | Loss: 11581761536.0 | Test Loss: 11219444736.0\n",
            "Epoch: 172 | Loss: 11219444736.0 | Test Loss: 10868542464.0\n",
            "Epoch: 173 | Loss: 10868542464.0 | Test Loss: 10529603584.0\n",
            "Epoch: 174 | Loss: 10529603584.0 | Test Loss: 10203136000.0\n",
            "Epoch: 175 | Loss: 10203136000.0 | Test Loss: 9889611776.0\n",
            "Epoch: 176 | Loss: 9889611776.0 | Test Loss: 9589453824.0\n",
            "Epoch: 177 | Loss: 9589453824.0 | Test Loss: 9303034880.0\n",
            "Epoch: 178 | Loss: 9303034880.0 | Test Loss: 9030676480.0\n",
            "Epoch: 179 | Loss: 9030676480.0 | Test Loss: 8772637696.0\n",
            "Epoch: 180 | Loss: 8772637696.0 | Test Loss: 8529117696.0\n",
            "Epoch: 181 | Loss: 8529117696.0 | Test Loss: 8300243968.0\n",
            "Epoch: 182 | Loss: 8300243968.0 | Test Loss: 8086077952.0\n",
            "Epoch: 183 | Loss: 8086077952.0 | Test Loss: 7886602752.0\n",
            "Epoch: 184 | Loss: 7886602752.0 | Test Loss: 7701731840.0\n",
            "Epoch: 185 | Loss: 7701731840.0 | Test Loss: 7531300352.0\n",
            "Epoch: 186 | Loss: 7531300352.0 | Test Loss: 7375066624.0\n",
            "Epoch: 187 | Loss: 7375066624.0 | Test Loss: 7232713728.0\n",
            "Epoch: 188 | Loss: 7232713728.0 | Test Loss: 7103851008.0\n",
            "Epoch: 189 | Loss: 7103851008.0 | Test Loss: 6988016640.0\n",
            "Epoch: 190 | Loss: 6988016640.0 | Test Loss: 6884683776.0\n",
            "Epoch: 191 | Loss: 6884683776.0 | Test Loss: 6793264640.0\n",
            "Epoch: 192 | Loss: 6793264640.0 | Test Loss: 6713115136.0\n",
            "Epoch: 193 | Loss: 6713115136.0 | Test Loss: 6643548160.0\n",
            "Epoch: 194 | Loss: 6643548160.0 | Test Loss: 6583833088.0\n",
            "Epoch: 195 | Loss: 6583833088.0 | Test Loss: 6533214208.0\n",
            "Epoch: 196 | Loss: 6533214208.0 | Test Loss: 6490913792.0\n",
            "Epoch: 197 | Loss: 6490913792.0 | Test Loss: 6456146944.0\n",
            "Epoch: 198 | Loss: 6456146944.0 | Test Loss: 6428125184.0\n",
            "Epoch: 199 | Loss: 6428125184.0 | Test Loss: 6406073856.0\n",
            "Epoch: 200 | Loss: 6406073856.0 | Test Loss: 6389235200.0\n",
            "Epoch: 201 | Loss: 6389235200.0 | Test Loss: 6376886784.0\n",
            "Epoch: 202 | Loss: 6376886784.0 | Test Loss: 6368333312.0\n",
            "Epoch: 203 | Loss: 6368333312.0 | Test Loss: 6362930688.0\n",
            "Epoch: 204 | Loss: 6362930688.0 | Test Loss: 6360081408.0\n",
            "Epoch: 205 | Loss: 6360081408.0 | Test Loss: 6359240704.0\n",
            "Epoch: 206 | Loss: 6359240704.0 | Test Loss: 6359920640.0\n",
            "Epoch: 207 | Loss: 6359920640.0 | Test Loss: 6361691136.0\n",
            "Epoch: 208 | Loss: 6361691136.0 | Test Loss: 6364180480.0\n",
            "Epoch: 209 | Loss: 6364180480.0 | Test Loss: 6367073280.0\n",
            "Epoch: 210 | Loss: 6367073280.0 | Test Loss: 6370108928.0\n",
            "Epoch: 211 | Loss: 6370108928.0 | Test Loss: 6373079552.0\n",
            "Epoch: 212 | Loss: 6373079552.0 | Test Loss: 6375822336.0\n",
            "Epoch: 213 | Loss: 6375822336.0 | Test Loss: 6378221056.0\n",
            "Epoch: 214 | Loss: 6378221056.0 | Test Loss: 6380194816.0\n",
            "Epoch: 215 | Loss: 6380194816.0 | Test Loss: 6381698560.0\n",
            "Epoch: 216 | Loss: 6381698560.0 | Test Loss: 6382714368.0\n",
            "Epoch: 217 | Loss: 6382714368.0 | Test Loss: 6383246336.0\n",
            "Epoch: 218 | Loss: 6383246336.0 | Test Loss: 6383318016.0\n",
            "Epoch: 219 | Loss: 6383318016.0 | Test Loss: 6382965760.0\n",
            "Epoch: 220 | Loss: 6382965760.0 | Test Loss: 6382238720.0\n",
            "Epoch: 221 | Loss: 6382238720.0 | Test Loss: 6381187072.0\n",
            "Epoch: 222 | Loss: 6381187072.0 | Test Loss: 6379869184.0\n",
            "Epoch: 223 | Loss: 6379869184.0 | Test Loss: 6378341888.0\n",
            "Epoch: 224 | Loss: 6378341888.0 | Test Loss: 6376660480.0\n",
            "Epoch: 225 | Loss: 6376660480.0 | Test Loss: 6374877696.0\n",
            "Epoch: 226 | Loss: 6374877696.0 | Test Loss: 6373041152.0\n",
            "Epoch: 227 | Loss: 6373041152.0 | Test Loss: 6371193856.0\n",
            "Epoch: 228 | Loss: 6371193856.0 | Test Loss: 6369373184.0\n",
            "Epoch: 229 | Loss: 6369373184.0 | Test Loss: 6367609344.0\n",
            "Epoch: 230 | Loss: 6367609344.0 | Test Loss: 6365928448.0\n",
            "Epoch: 231 | Loss: 6365928448.0 | Test Loss: 6364348416.0\n",
            "Epoch: 232 | Loss: 6364348416.0 | Test Loss: 6362884096.0\n",
            "Epoch: 233 | Loss: 6362884096.0 | Test Loss: 6361543168.0\n",
            "Epoch: 234 | Loss: 6361543168.0 | Test Loss: 6360332800.0\n",
            "Epoch: 235 | Loss: 6360332800.0 | Test Loss: 6359251456.0\n",
            "Epoch: 236 | Loss: 6359251456.0 | Test Loss: 6358298624.0\n",
            "Epoch: 237 | Loss: 6358298624.0 | Test Loss: 6357469696.0\n",
            "Epoch: 238 | Loss: 6357469696.0 | Test Loss: 6356758016.0\n",
            "Epoch: 239 | Loss: 6356758016.0 | Test Loss: 6356152832.0\n",
            "Epoch: 240 | Loss: 6356152832.0 | Test Loss: 6355646976.0\n",
            "Epoch: 241 | Loss: 6355646976.0 | Test Loss: 6355230208.0\n",
            "Epoch: 242 | Loss: 6355230208.0 | Test Loss: 6354890240.0\n",
            "Epoch: 243 | Loss: 6354890240.0 | Test Loss: 6354619392.0\n",
            "Epoch: 244 | Loss: 6354619392.0 | Test Loss: 6354405888.0\n",
            "Epoch: 245 | Loss: 6354405888.0 | Test Loss: 6354240512.0\n",
            "Epoch: 246 | Loss: 6354240512.0 | Test Loss: 6354114560.0\n",
            "Epoch: 247 | Loss: 6354114560.0 | Test Loss: 6354021376.0\n",
            "Epoch: 248 | Loss: 6354021376.0 | Test Loss: 6353951744.0\n",
            "Epoch: 249 | Loss: 6353951744.0 | Test Loss: 6353900032.0\n",
            "Epoch: 250 | Loss: 6353900032.0 | Test Loss: 6353860608.0\n",
            "Epoch: 251 | Loss: 6353860608.0 | Test Loss: 6353828864.0\n",
            "Epoch: 252 | Loss: 6353828864.0 | Test Loss: 6353801216.0\n",
            "Epoch: 253 | Loss: 6353801216.0 | Test Loss: 6353774080.0\n",
            "Epoch: 254 | Loss: 6353774080.0 | Test Loss: 6353745408.0\n",
            "Epoch: 255 | Loss: 6353745408.0 | Test Loss: 6353712640.0\n",
            "Epoch: 256 | Loss: 6353712640.0 | Test Loss: 6353677312.0\n",
            "Epoch: 257 | Loss: 6353677312.0 | Test Loss: 6353635328.0\n",
            "Epoch: 258 | Loss: 6353635328.0 | Test Loss: 6353588224.0\n",
            "Epoch: 259 | Loss: 6353588224.0 | Test Loss: 6353536000.0\n",
            "Epoch: 260 | Loss: 6353536000.0 | Test Loss: 6353478144.0\n",
            "Epoch: 261 | Loss: 6353478144.0 | Test Loss: 6353415168.0\n",
            "Epoch: 262 | Loss: 6353415168.0 | Test Loss: 6353348096.0\n",
            "Epoch: 263 | Loss: 6353348096.0 | Test Loss: 6353276928.0\n",
            "Epoch: 264 | Loss: 6353276928.0 | Test Loss: 6353202688.0\n",
            "Epoch: 265 | Loss: 6353202688.0 | Test Loss: 6353127424.0\n",
            "Epoch: 266 | Loss: 6353127424.0 | Test Loss: 6353050112.0\n",
            "Epoch: 267 | Loss: 6353050112.0 | Test Loss: 6352972800.0\n",
            "Epoch: 268 | Loss: 6352972800.0 | Test Loss: 6352893440.0\n",
            "Epoch: 269 | Loss: 6352893440.0 | Test Loss: 6352817152.0\n",
            "Epoch: 270 | Loss: 6352817152.0 | Test Loss: 6352740352.0\n",
            "Epoch: 271 | Loss: 6352740352.0 | Test Loss: 6352664576.0\n",
            "Epoch: 272 | Loss: 6352664576.0 | Test Loss: 6352591360.0\n",
            "Epoch: 273 | Loss: 6352591360.0 | Test Loss: 6352518656.0\n",
            "Epoch: 274 | Loss: 6352518656.0 | Test Loss: 6352448512.0\n",
            "Epoch: 275 | Loss: 6352448512.0 | Test Loss: 6352381440.0\n",
            "Epoch: 276 | Loss: 6352381440.0 | Test Loss: 6352316416.0\n",
            "Epoch: 277 | Loss: 6352316416.0 | Test Loss: 6352252928.0\n",
            "Epoch: 278 | Loss: 6352252928.0 | Test Loss: 6352190976.0\n",
            "Epoch: 279 | Loss: 6352190976.0 | Test Loss: 6352133120.0\n",
            "Epoch: 280 | Loss: 6352133120.0 | Test Loss: 6352075264.0\n",
            "Epoch: 281 | Loss: 6352075264.0 | Test Loss: 6352020992.0\n",
            "Epoch: 282 | Loss: 6352020992.0 | Test Loss: 6351967744.0\n",
            "Epoch: 283 | Loss: 6351967744.0 | Test Loss: 6351916544.0\n",
            "Epoch: 284 | Loss: 6351916544.0 | Test Loss: 6351864832.0\n",
            "Epoch: 285 | Loss: 6351864832.0 | Test Loss: 6351815168.0\n",
            "Epoch: 286 | Loss: 6351815168.0 | Test Loss: 6351767552.0\n",
            "Epoch: 287 | Loss: 6351767552.0 | Test Loss: 6351719936.0\n",
            "Epoch: 288 | Loss: 6351719936.0 | Test Loss: 6351674368.0\n",
            "Epoch: 289 | Loss: 6351674368.0 | Test Loss: 6351629312.0\n",
            "Epoch: 290 | Loss: 6351629312.0 | Test Loss: 6351585280.0\n",
            "Epoch: 291 | Loss: 6351585280.0 | Test Loss: 6351541248.0\n",
            "Epoch: 292 | Loss: 6351541248.0 | Test Loss: 6351497216.0\n",
            "Epoch: 293 | Loss: 6351497216.0 | Test Loss: 6351454208.0\n",
            "Epoch: 294 | Loss: 6351454208.0 | Test Loss: 6351410688.0\n",
            "Epoch: 295 | Loss: 6351410688.0 | Test Loss: 6351367168.0\n",
            "Epoch: 296 | Loss: 6351367168.0 | Test Loss: 6351325184.0\n",
            "Epoch: 297 | Loss: 6351325184.0 | Test Loss: 6351282688.0\n",
            "Epoch: 298 | Loss: 6351282688.0 | Test Loss: 6351239680.0\n",
            "Epoch: 299 | Loss: 6351239680.0 | Test Loss: 6351197184.0\n",
            "Epoch: 300 | Loss: 6351197184.0 | Test Loss: 6351155712.0\n",
            "Epoch: 301 | Loss: 6351155712.0 | Test Loss: 6351112704.0\n",
            "Epoch: 302 | Loss: 6351112704.0 | Test Loss: 6351070720.0\n",
            "Epoch: 303 | Loss: 6351070720.0 | Test Loss: 6351028224.0\n",
            "Epoch: 304 | Loss: 6351028224.0 | Test Loss: 6350986752.0\n",
            "Epoch: 305 | Loss: 6350986752.0 | Test Loss: 6350946304.0\n",
            "Epoch: 306 | Loss: 6350946304.0 | Test Loss: 6350904832.0\n",
            "Epoch: 307 | Loss: 6350904832.0 | Test Loss: 6350862848.0\n",
            "Epoch: 308 | Loss: 6350862848.0 | Test Loss: 6350822400.0\n",
            "Epoch: 309 | Loss: 6350822400.0 | Test Loss: 6350781440.0\n",
            "Epoch: 310 | Loss: 6350781440.0 | Test Loss: 6350740992.0\n",
            "Epoch: 311 | Loss: 6350740992.0 | Test Loss: 6350701568.0\n",
            "Epoch: 312 | Loss: 6350701568.0 | Test Loss: 6350662144.0\n",
            "Epoch: 313 | Loss: 6350662144.0 | Test Loss: 6350621696.0\n",
            "Epoch: 314 | Loss: 6350621696.0 | Test Loss: 6350581760.0\n",
            "Epoch: 315 | Loss: 6350581760.0 | Test Loss: 6350542848.0\n",
            "Epoch: 316 | Loss: 6350542848.0 | Test Loss: 6350503936.0\n",
            "Epoch: 317 | Loss: 6350503936.0 | Test Loss: 6350464512.0\n",
            "Epoch: 318 | Loss: 6350464512.0 | Test Loss: 6350426624.0\n",
            "Epoch: 319 | Loss: 6350426624.0 | Test Loss: 6350388224.0\n",
            "Epoch: 320 | Loss: 6350388224.0 | Test Loss: 6350349824.0\n",
            "Epoch: 321 | Loss: 6350349824.0 | Test Loss: 6350311424.0\n",
            "Epoch: 322 | Loss: 6350311424.0 | Test Loss: 6350275584.0\n",
            "Epoch: 323 | Loss: 6350275584.0 | Test Loss: 6350237184.0\n",
            "Epoch: 324 | Loss: 6350237184.0 | Test Loss: 6350200832.0\n",
            "Epoch: 325 | Loss: 6350200832.0 | Test Loss: 6350163456.0\n",
            "Epoch: 326 | Loss: 6350163456.0 | Test Loss: 6350126080.0\n",
            "Epoch: 327 | Loss: 6350126080.0 | Test Loss: 6350089728.0\n",
            "Epoch: 328 | Loss: 6350089728.0 | Test Loss: 6350053888.0\n",
            "Epoch: 329 | Loss: 6350053888.0 | Test Loss: 6350017024.0\n",
            "Epoch: 330 | Loss: 6350017024.0 | Test Loss: 6349981184.0\n",
            "Epoch: 331 | Loss: 6349981184.0 | Test Loss: 6349944320.0\n",
            "Epoch: 332 | Loss: 6349944320.0 | Test Loss: 6349908480.0\n",
            "Epoch: 333 | Loss: 6349908480.0 | Test Loss: 6349873152.0\n",
            "Epoch: 334 | Loss: 6349873152.0 | Test Loss: 6349836800.0\n",
            "Epoch: 335 | Loss: 6349836800.0 | Test Loss: 6349802496.0\n",
            "Epoch: 336 | Loss: 6349802496.0 | Test Loss: 6349767168.0\n",
            "Epoch: 337 | Loss: 6349767168.0 | Test Loss: 6349731840.0\n",
            "Epoch: 338 | Loss: 6349731840.0 | Test Loss: 6349697024.0\n",
            "Epoch: 339 | Loss: 6349697024.0 | Test Loss: 6349662208.0\n",
            "Epoch: 340 | Loss: 6349662208.0 | Test Loss: 6349627904.0\n",
            "Epoch: 341 | Loss: 6349627904.0 | Test Loss: 6349593600.0\n",
            "Epoch: 342 | Loss: 6349593600.0 | Test Loss: 6349558784.0\n",
            "Epoch: 343 | Loss: 6349558784.0 | Test Loss: 6349524480.0\n",
            "Epoch: 344 | Loss: 6349524480.0 | Test Loss: 6349490688.0\n",
            "Epoch: 345 | Loss: 6349490688.0 | Test Loss: 6349456896.0\n",
            "Epoch: 346 | Loss: 6349456896.0 | Test Loss: 6349424128.0\n",
            "Epoch: 347 | Loss: 6349424128.0 | Test Loss: 6349390336.0\n",
            "Epoch: 348 | Loss: 6349390336.0 | Test Loss: 6349356544.0\n",
            "Epoch: 349 | Loss: 6349356544.0 | Test Loss: 6349323264.0\n",
            "Epoch: 350 | Loss: 6349323264.0 | Test Loss: 6349290496.0\n",
            "Epoch: 351 | Loss: 6349290496.0 | Test Loss: 6349257216.0\n",
            "Epoch: 352 | Loss: 6349257216.0 | Test Loss: 6349224960.0\n",
            "Epoch: 353 | Loss: 6349224960.0 | Test Loss: 6349192192.0\n",
            "Epoch: 354 | Loss: 6349192192.0 | Test Loss: 6349158912.0\n",
            "Epoch: 355 | Loss: 6349158912.0 | Test Loss: 6349126656.0\n",
            "Epoch: 356 | Loss: 6349126656.0 | Test Loss: 6349094400.0\n",
            "Epoch: 357 | Loss: 6349094400.0 | Test Loss: 6349061632.0\n",
            "Epoch: 358 | Loss: 6349061632.0 | Test Loss: 6349029376.0\n",
            "Epoch: 359 | Loss: 6349029376.0 | Test Loss: 6348997632.0\n",
            "Epoch: 360 | Loss: 6348997632.0 | Test Loss: 6348965376.0\n",
            "Epoch: 361 | Loss: 6348965376.0 | Test Loss: 6348933120.0\n",
            "Epoch: 362 | Loss: 6348933120.0 | Test Loss: 6348901376.0\n",
            "Epoch: 363 | Loss: 6348901376.0 | Test Loss: 6348870144.0\n",
            "Epoch: 364 | Loss: 6348870144.0 | Test Loss: 6348839424.0\n",
            "Epoch: 365 | Loss: 6348839424.0 | Test Loss: 6348808192.0\n",
            "Epoch: 366 | Loss: 6348808192.0 | Test Loss: 6348777472.0\n",
            "Epoch: 367 | Loss: 6348777472.0 | Test Loss: 6348747264.0\n",
            "Epoch: 368 | Loss: 6348747264.0 | Test Loss: 6348716544.0\n",
            "Epoch: 369 | Loss: 6348716544.0 | Test Loss: 6348685824.0\n",
            "Epoch: 370 | Loss: 6348685824.0 | Test Loss: 6348655616.0\n",
            "Epoch: 371 | Loss: 6348655616.0 | Test Loss: 6348624896.0\n",
            "Epoch: 372 | Loss: 6348624896.0 | Test Loss: 6348594688.0\n",
            "Epoch: 373 | Loss: 6348594688.0 | Test Loss: 6348565504.0\n",
            "Epoch: 374 | Loss: 6348565504.0 | Test Loss: 6348535808.0\n",
            "Epoch: 375 | Loss: 6348535808.0 | Test Loss: 6348505600.0\n",
            "Epoch: 376 | Loss: 6348505600.0 | Test Loss: 6348475392.0\n",
            "Epoch: 377 | Loss: 6348475392.0 | Test Loss: 6348446208.0\n",
            "Epoch: 378 | Loss: 6348446208.0 | Test Loss: 6348416512.0\n",
            "Epoch: 379 | Loss: 6348416512.0 | Test Loss: 6348387328.0\n",
            "Epoch: 380 | Loss: 6348387328.0 | Test Loss: 6348358656.0\n",
            "Epoch: 381 | Loss: 6348358656.0 | Test Loss: 6348328960.0\n",
            "Epoch: 382 | Loss: 6348328960.0 | Test Loss: 6348299776.0\n",
            "Epoch: 383 | Loss: 6348299776.0 | Test Loss: 6348271104.0\n",
            "Epoch: 384 | Loss: 6348271104.0 | Test Loss: 6348241408.0\n",
            "Epoch: 385 | Loss: 6348241408.0 | Test Loss: 6348213248.0\n",
            "Epoch: 386 | Loss: 6348213248.0 | Test Loss: 6348184576.0\n",
            "Epoch: 387 | Loss: 6348184576.0 | Test Loss: 6348155904.0\n",
            "Epoch: 388 | Loss: 6348155904.0 | Test Loss: 6348126720.0\n",
            "Epoch: 389 | Loss: 6348126720.0 | Test Loss: 6348099072.0\n",
            "Epoch: 390 | Loss: 6348099072.0 | Test Loss: 6348070400.0\n",
            "Epoch: 391 | Loss: 6348070400.0 | Test Loss: 6348041728.0\n",
            "Epoch: 392 | Loss: 6348041728.0 | Test Loss: 6348014080.0\n",
            "Epoch: 393 | Loss: 6348014080.0 | Test Loss: 6347985408.0\n",
            "Epoch: 394 | Loss: 6347985408.0 | Test Loss: 6347957248.0\n",
            "Epoch: 395 | Loss: 6347957248.0 | Test Loss: 6347928576.0\n",
            "Epoch: 396 | Loss: 6347928576.0 | Test Loss: 6347899904.0\n",
            "Epoch: 397 | Loss: 6347899904.0 | Test Loss: 6347872256.0\n",
            "Epoch: 398 | Loss: 6347872256.0 | Test Loss: 6347844096.0\n",
            "Epoch: 399 | Loss: 6347844096.0 | Test Loss: 6347815936.0\n",
            "Epoch: 400 | Loss: 6347815936.0 | Test Loss: 6347788288.0\n",
            "Epoch: 401 | Loss: 6347788288.0 | Test Loss: 6347759616.0\n",
            "Epoch: 402 | Loss: 6347759616.0 | Test Loss: 6347732480.0\n",
            "Epoch: 403 | Loss: 6347732480.0 | Test Loss: 6347704832.0\n",
            "Epoch: 404 | Loss: 6347704832.0 | Test Loss: 6347677696.0\n",
            "Epoch: 405 | Loss: 6347677696.0 | Test Loss: 6347649536.0\n",
            "Epoch: 406 | Loss: 6347649536.0 | Test Loss: 6347621888.0\n",
            "Epoch: 407 | Loss: 6347621888.0 | Test Loss: 6347594752.0\n",
            "Epoch: 408 | Loss: 6347594752.0 | Test Loss: 6347567616.0\n",
            "Epoch: 409 | Loss: 6347567616.0 | Test Loss: 6347539968.0\n",
            "Epoch: 410 | Loss: 6347539968.0 | Test Loss: 6347511808.0\n",
            "Epoch: 411 | Loss: 6347511808.0 | Test Loss: 6347485696.0\n",
            "Epoch: 412 | Loss: 6347485696.0 | Test Loss: 6347458560.0\n",
            "Epoch: 413 | Loss: 6347458560.0 | Test Loss: 6347430912.0\n",
            "Epoch: 414 | Loss: 6347430912.0 | Test Loss: 6347404288.0\n",
            "Epoch: 415 | Loss: 6347404288.0 | Test Loss: 6347377664.0\n",
            "Epoch: 416 | Loss: 6347377664.0 | Test Loss: 6347351552.0\n",
            "Epoch: 417 | Loss: 6347351552.0 | Test Loss: 6347324928.0\n",
            "Epoch: 418 | Loss: 6347324928.0 | Test Loss: 6347298304.0\n",
            "Epoch: 419 | Loss: 6347298304.0 | Test Loss: 6347272192.0\n",
            "Epoch: 420 | Loss: 6347272192.0 | Test Loss: 6347245056.0\n",
            "Epoch: 421 | Loss: 6347245056.0 | Test Loss: 6347218432.0\n",
            "Epoch: 422 | Loss: 6347218432.0 | Test Loss: 6347192832.0\n",
            "Epoch: 423 | Loss: 6347192832.0 | Test Loss: 6347167232.0\n",
            "Epoch: 424 | Loss: 6347167232.0 | Test Loss: 6347141120.0\n",
            "Epoch: 425 | Loss: 6347141120.0 | Test Loss: 6347115520.0\n",
            "Epoch: 426 | Loss: 6347115520.0 | Test Loss: 6347088384.0\n",
            "Epoch: 427 | Loss: 6347088384.0 | Test Loss: 6347063296.0\n",
            "Epoch: 428 | Loss: 6347063296.0 | Test Loss: 6347037696.0\n",
            "Epoch: 429 | Loss: 6347037696.0 | Test Loss: 6347011584.0\n",
            "Epoch: 430 | Loss: 6347011584.0 | Test Loss: 6346985984.0\n",
            "Epoch: 431 | Loss: 6346985984.0 | Test Loss: 6346960384.0\n",
            "Epoch: 432 | Loss: 6346960384.0 | Test Loss: 6346934272.0\n",
            "Epoch: 433 | Loss: 6346934272.0 | Test Loss: 6346909696.0\n",
            "Epoch: 434 | Loss: 6346909696.0 | Test Loss: 6346884096.0\n",
            "Epoch: 435 | Loss: 6346884096.0 | Test Loss: 6346858496.0\n",
            "Epoch: 436 | Loss: 6346858496.0 | Test Loss: 6346833920.0\n",
            "Epoch: 437 | Loss: 6346833920.0 | Test Loss: 6346808320.0\n",
            "Epoch: 438 | Loss: 6346808320.0 | Test Loss: 6346783232.0\n",
            "Epoch: 439 | Loss: 6346783232.0 | Test Loss: 6346757632.0\n",
            "Epoch: 440 | Loss: 6346757632.0 | Test Loss: 6346733056.0\n",
            "Epoch: 441 | Loss: 6346733056.0 | Test Loss: 6346707456.0\n",
            "Epoch: 442 | Loss: 6346707456.0 | Test Loss: 6346682368.0\n",
            "Epoch: 443 | Loss: 6346682368.0 | Test Loss: 6346657280.0\n",
            "Epoch: 444 | Loss: 6346657280.0 | Test Loss: 6346632704.0\n",
            "Epoch: 445 | Loss: 6346632704.0 | Test Loss: 6346607616.0\n",
            "Epoch: 446 | Loss: 6346607616.0 | Test Loss: 6346583552.0\n",
            "Epoch: 447 | Loss: 6346583552.0 | Test Loss: 6346558464.0\n",
            "Epoch: 448 | Loss: 6346558464.0 | Test Loss: 6346533376.0\n",
            "Epoch: 449 | Loss: 6346533376.0 | Test Loss: 6346509312.0\n",
            "Epoch: 450 | Loss: 6346509312.0 | Test Loss: 6346484736.0\n",
            "Epoch: 451 | Loss: 6346484736.0 | Test Loss: 6346460672.0\n",
            "Epoch: 452 | Loss: 6346460672.0 | Test Loss: 6346436096.0\n",
            "Epoch: 453 | Loss: 6346436096.0 | Test Loss: 6346411008.0\n",
            "Epoch: 454 | Loss: 6346411008.0 | Test Loss: 6346386944.0\n",
            "Epoch: 455 | Loss: 6346386944.0 | Test Loss: 6346362368.0\n",
            "Epoch: 456 | Loss: 6346362368.0 | Test Loss: 6346338304.0\n",
            "Epoch: 457 | Loss: 6346338304.0 | Test Loss: 6346313728.0\n",
            "Epoch: 458 | Loss: 6346313728.0 | Test Loss: 6346289664.0\n",
            "Epoch: 459 | Loss: 6346289664.0 | Test Loss: 6346265088.0\n",
            "Epoch: 460 | Loss: 6346265088.0 | Test Loss: 6346241536.0\n",
            "Epoch: 461 | Loss: 6346241536.0 | Test Loss: 6346216960.0\n",
            "Epoch: 462 | Loss: 6346216960.0 | Test Loss: 6346192384.0\n",
            "Epoch: 463 | Loss: 6346192384.0 | Test Loss: 6346168832.0\n",
            "Epoch: 464 | Loss: 6346168832.0 | Test Loss: 6346144256.0\n",
            "Epoch: 465 | Loss: 6346144256.0 | Test Loss: 6346120704.0\n",
            "Epoch: 466 | Loss: 6346120704.0 | Test Loss: 6346096128.0\n",
            "Epoch: 467 | Loss: 6346096128.0 | Test Loss: 6346073088.0\n",
            "Epoch: 468 | Loss: 6346073088.0 | Test Loss: 6346049024.0\n",
            "Epoch: 469 | Loss: 6346049024.0 | Test Loss: 6346025472.0\n",
            "Epoch: 470 | Loss: 6346025472.0 | Test Loss: 6346001408.0\n",
            "Epoch: 471 | Loss: 6346001408.0 | Test Loss: 6345977344.0\n",
            "Epoch: 472 | Loss: 6345977344.0 | Test Loss: 6345953792.0\n",
            "Epoch: 473 | Loss: 6345953792.0 | Test Loss: 6345930240.0\n",
            "Epoch: 474 | Loss: 6345930240.0 | Test Loss: 6345906176.0\n",
            "Epoch: 475 | Loss: 6345906176.0 | Test Loss: 6345883136.0\n",
            "Epoch: 476 | Loss: 6345883136.0 | Test Loss: 6345859584.0\n",
            "Epoch: 477 | Loss: 6345859584.0 | Test Loss: 6345835520.0\n",
            "Epoch: 478 | Loss: 6345835520.0 | Test Loss: 6345811968.0\n",
            "Epoch: 479 | Loss: 6345811968.0 | Test Loss: 6345787904.0\n",
            "Epoch: 480 | Loss: 6345787904.0 | Test Loss: 6345764864.0\n",
            "Epoch: 481 | Loss: 6345764864.0 | Test Loss: 6345741312.0\n",
            "Epoch: 482 | Loss: 6345741312.0 | Test Loss: 6345717760.0\n",
            "Epoch: 483 | Loss: 6345717760.0 | Test Loss: 6345694720.0\n",
            "Epoch: 484 | Loss: 6345694720.0 | Test Loss: 6345671168.0\n",
            "Epoch: 485 | Loss: 6345671168.0 | Test Loss: 6345648128.0\n",
            "Epoch: 486 | Loss: 6345648128.0 | Test Loss: 6345624064.0\n",
            "Epoch: 487 | Loss: 6345624064.0 | Test Loss: 6345601536.0\n",
            "Epoch: 488 | Loss: 6345601536.0 | Test Loss: 6345577984.0\n",
            "Epoch: 489 | Loss: 6345577984.0 | Test Loss: 6345554432.0\n",
            "Epoch: 490 | Loss: 6345554432.0 | Test Loss: 6345531904.0\n",
            "Epoch: 491 | Loss: 6345531904.0 | Test Loss: 6345507840.0\n",
            "Epoch: 492 | Loss: 6345507840.0 | Test Loss: 6345484800.0\n",
            "Epoch: 493 | Loss: 6345484800.0 | Test Loss: 6345462784.0\n",
            "Epoch: 494 | Loss: 6345462784.0 | Test Loss: 6345438720.0\n",
            "Epoch: 495 | Loss: 6345438720.0 | Test Loss: 6345415680.0\n",
            "Epoch: 496 | Loss: 6345415680.0 | Test Loss: 6345393152.0\n",
            "Epoch: 497 | Loss: 6345393152.0 | Test Loss: 6345370112.0\n",
            "Epoch: 498 | Loss: 6345370112.0 | Test Loss: 6345347072.0\n",
            "Epoch: 499 | Loss: 6345347072.0 | Test Loss: 6345324544.0\n",
            "Epoch: 500 | Loss: 6345324544.0 | Test Loss: 6345302528.0\n",
            "Epoch: 501 | Loss: 6345302528.0 | Test Loss: 6345278976.0\n",
            "Epoch: 502 | Loss: 6345278976.0 | Test Loss: 6345255936.0\n",
            "Epoch: 503 | Loss: 6345255936.0 | Test Loss: 6345233408.0\n",
            "Epoch: 504 | Loss: 6345233408.0 | Test Loss: 6345210880.0\n",
            "Epoch: 505 | Loss: 6345210880.0 | Test Loss: 6345187840.0\n",
            "Epoch: 506 | Loss: 6345187840.0 | Test Loss: 6345165824.0\n",
            "Epoch: 507 | Loss: 6345165824.0 | Test Loss: 6345143296.0\n",
            "Epoch: 508 | Loss: 6345143296.0 | Test Loss: 6345120768.0\n",
            "Epoch: 509 | Loss: 6345120768.0 | Test Loss: 6345097728.0\n",
            "Epoch: 510 | Loss: 6345097728.0 | Test Loss: 6345075200.0\n",
            "Epoch: 511 | Loss: 6345075200.0 | Test Loss: 6345053696.0\n",
            "Epoch: 512 | Loss: 6345053696.0 | Test Loss: 6345029632.0\n",
            "Epoch: 513 | Loss: 6345029632.0 | Test Loss: 6345008128.0\n",
            "Epoch: 514 | Loss: 6345008128.0 | Test Loss: 6344985600.0\n",
            "Epoch: 515 | Loss: 6344985600.0 | Test Loss: 6344963072.0\n",
            "Epoch: 516 | Loss: 6344963072.0 | Test Loss: 6344941056.0\n",
            "Epoch: 517 | Loss: 6344941056.0 | Test Loss: 6344919040.0\n",
            "Epoch: 518 | Loss: 6344919040.0 | Test Loss: 6344896000.0\n",
            "Epoch: 519 | Loss: 6344896000.0 | Test Loss: 6344873984.0\n",
            "Epoch: 520 | Loss: 6344873984.0 | Test Loss: 6344852480.0\n",
            "Epoch: 521 | Loss: 6344852480.0 | Test Loss: 6344830464.0\n",
            "Epoch: 522 | Loss: 6344830464.0 | Test Loss: 6344808448.0\n",
            "Epoch: 523 | Loss: 6344808448.0 | Test Loss: 6344785920.0\n",
            "Epoch: 524 | Loss: 6344785920.0 | Test Loss: 6344763904.0\n",
            "Epoch: 525 | Loss: 6344763904.0 | Test Loss: 6344741888.0\n",
            "Epoch: 526 | Loss: 6344741888.0 | Test Loss: 6344719872.0\n",
            "Epoch: 527 | Loss: 6344719872.0 | Test Loss: 6344698368.0\n",
            "Epoch: 528 | Loss: 6344698368.0 | Test Loss: 6344676352.0\n",
            "Epoch: 529 | Loss: 6344676352.0 | Test Loss: 6344655360.0\n",
            "Epoch: 530 | Loss: 6344655360.0 | Test Loss: 6344632832.0\n",
            "Epoch: 531 | Loss: 6344632832.0 | Test Loss: 6344610816.0\n",
            "Epoch: 532 | Loss: 6344610816.0 | Test Loss: 6344589312.0\n",
            "Epoch: 533 | Loss: 6344589312.0 | Test Loss: 6344566784.0\n",
            "Epoch: 534 | Loss: 6344566784.0 | Test Loss: 6344545792.0\n",
            "Epoch: 535 | Loss: 6344545792.0 | Test Loss: 6344523776.0\n",
            "Epoch: 536 | Loss: 6344523776.0 | Test Loss: 6344502272.0\n",
            "Epoch: 537 | Loss: 6344502272.0 | Test Loss: 6344480256.0\n",
            "Epoch: 538 | Loss: 6344480256.0 | Test Loss: 6344458752.0\n",
            "Epoch: 539 | Loss: 6344458752.0 | Test Loss: 6344437248.0\n",
            "Epoch: 540 | Loss: 6344437248.0 | Test Loss: 6344415232.0\n",
            "Epoch: 541 | Loss: 6344415232.0 | Test Loss: 6344394752.0\n",
            "Epoch: 542 | Loss: 6344394752.0 | Test Loss: 6344373248.0\n",
            "Epoch: 543 | Loss: 6344373248.0 | Test Loss: 6344351232.0\n",
            "Epoch: 544 | Loss: 6344351232.0 | Test Loss: 6344330240.0\n",
            "Epoch: 545 | Loss: 6344330240.0 | Test Loss: 6344308224.0\n",
            "Epoch: 546 | Loss: 6344308224.0 | Test Loss: 6344286720.0\n",
            "Epoch: 547 | Loss: 6344286720.0 | Test Loss: 6344265216.0\n",
            "Epoch: 548 | Loss: 6344265216.0 | Test Loss: 6344244224.0\n",
            "Epoch: 549 | Loss: 6344244224.0 | Test Loss: 6344222208.0\n",
            "Epoch: 550 | Loss: 6344222208.0 | Test Loss: 6344201216.0\n",
            "Epoch: 551 | Loss: 6344201216.0 | Test Loss: 6344180224.0\n",
            "Epoch: 552 | Loss: 6344180224.0 | Test Loss: 6344158720.0\n",
            "Epoch: 553 | Loss: 6344158720.0 | Test Loss: 6344136704.0\n",
            "Epoch: 554 | Loss: 6344136704.0 | Test Loss: 6344116736.0\n",
            "Epoch: 555 | Loss: 6344116736.0 | Test Loss: 6344095232.0\n",
            "Epoch: 556 | Loss: 6344095232.0 | Test Loss: 6344073728.0\n",
            "Epoch: 557 | Loss: 6344073728.0 | Test Loss: 6344053248.0\n",
            "Epoch: 558 | Loss: 6344053248.0 | Test Loss: 6344031744.0\n",
            "Epoch: 559 | Loss: 6344031744.0 | Test Loss: 6344010752.0\n",
            "Epoch: 560 | Loss: 6344010752.0 | Test Loss: 6343989248.0\n",
            "Epoch: 561 | Loss: 6343989248.0 | Test Loss: 6343968768.0\n",
            "Epoch: 562 | Loss: 6343968768.0 | Test Loss: 6343948288.0\n",
            "Epoch: 563 | Loss: 6343948288.0 | Test Loss: 6343927296.0\n",
            "Epoch: 564 | Loss: 6343927296.0 | Test Loss: 6343906304.0\n",
            "Epoch: 565 | Loss: 6343906304.0 | Test Loss: 6343884800.0\n",
            "Epoch: 566 | Loss: 6343884800.0 | Test Loss: 6343864320.0\n",
            "Epoch: 567 | Loss: 6343864320.0 | Test Loss: 6343843328.0\n",
            "Epoch: 568 | Loss: 6343843328.0 | Test Loss: 6343821824.0\n",
            "Epoch: 569 | Loss: 6343821824.0 | Test Loss: 6343801856.0\n",
            "Epoch: 570 | Loss: 6343801856.0 | Test Loss: 6343780864.0\n",
            "Epoch: 571 | Loss: 6343780864.0 | Test Loss: 6343760384.0\n",
            "Epoch: 572 | Loss: 6343760384.0 | Test Loss: 6343739392.0\n",
            "Epoch: 573 | Loss: 6343739392.0 | Test Loss: 6343718400.0\n",
            "Epoch: 574 | Loss: 6343718400.0 | Test Loss: 6343696896.0\n",
            "Epoch: 575 | Loss: 6343696896.0 | Test Loss: 6343676928.0\n",
            "Epoch: 576 | Loss: 6343676928.0 | Test Loss: 6343657472.0\n",
            "Epoch: 577 | Loss: 6343657472.0 | Test Loss: 6343635968.0\n",
            "Epoch: 578 | Loss: 6343635968.0 | Test Loss: 6343615488.0\n",
            "Epoch: 579 | Loss: 6343615488.0 | Test Loss: 6343595008.0\n",
            "Epoch: 580 | Loss: 6343595008.0 | Test Loss: 6343573504.0\n",
            "Epoch: 581 | Loss: 6343573504.0 | Test Loss: 6343553536.0\n",
            "Epoch: 582 | Loss: 6343553536.0 | Test Loss: 6343533056.0\n",
            "Epoch: 583 | Loss: 6343533056.0 | Test Loss: 6343513088.0\n",
            "Epoch: 584 | Loss: 6343513088.0 | Test Loss: 6343492096.0\n",
            "Epoch: 585 | Loss: 6343492096.0 | Test Loss: 6343471616.0\n",
            "Epoch: 586 | Loss: 6343471616.0 | Test Loss: 6343451136.0\n",
            "Epoch: 587 | Loss: 6343451136.0 | Test Loss: 6343431680.0\n",
            "Epoch: 588 | Loss: 6343431680.0 | Test Loss: 6343410688.0\n",
            "Epoch: 589 | Loss: 6343410688.0 | Test Loss: 6343390208.0\n",
            "Epoch: 590 | Loss: 6343390208.0 | Test Loss: 6343371264.0\n",
            "Epoch: 591 | Loss: 6343371264.0 | Test Loss: 6343350272.0\n",
            "Epoch: 592 | Loss: 6343350272.0 | Test Loss: 6343329792.0\n",
            "Epoch: 593 | Loss: 6343329792.0 | Test Loss: 6343309824.0\n",
            "Epoch: 594 | Loss: 6343309824.0 | Test Loss: 6343289856.0\n",
            "Epoch: 595 | Loss: 6343289856.0 | Test Loss: 6343270400.0\n",
            "Epoch: 596 | Loss: 6343270400.0 | Test Loss: 6343250432.0\n",
            "Epoch: 597 | Loss: 6343250432.0 | Test Loss: 6343230464.0\n",
            "Epoch: 598 | Loss: 6343230464.0 | Test Loss: 6343210496.0\n",
            "Epoch: 599 | Loss: 6343210496.0 | Test Loss: 6343190528.0\n",
            "Epoch: 600 | Loss: 6343190528.0 | Test Loss: 6343171072.0\n",
            "Epoch: 601 | Loss: 6343171072.0 | Test Loss: 6343150592.0\n",
            "Epoch: 602 | Loss: 6343150592.0 | Test Loss: 6343131136.0\n",
            "Epoch: 603 | Loss: 6343131136.0 | Test Loss: 6343110656.0\n",
            "Epoch: 604 | Loss: 6343110656.0 | Test Loss: 6343091200.0\n",
            "Epoch: 605 | Loss: 6343091200.0 | Test Loss: 6343071744.0\n",
            "Epoch: 606 | Loss: 6343071744.0 | Test Loss: 6343052288.0\n",
            "Epoch: 607 | Loss: 6343052288.0 | Test Loss: 6343032832.0\n",
            "Epoch: 608 | Loss: 6343032832.0 | Test Loss: 6343012352.0\n",
            "Epoch: 609 | Loss: 6343012352.0 | Test Loss: 6342993408.0\n",
            "Epoch: 610 | Loss: 6342993408.0 | Test Loss: 6342972928.0\n",
            "Epoch: 611 | Loss: 6342972928.0 | Test Loss: 6342954496.0\n",
            "Epoch: 612 | Loss: 6342954496.0 | Test Loss: 6342934528.0\n",
            "Epoch: 613 | Loss: 6342934528.0 | Test Loss: 6342914560.0\n",
            "Epoch: 614 | Loss: 6342914560.0 | Test Loss: 6342895616.0\n",
            "Epoch: 615 | Loss: 6342895616.0 | Test Loss: 6342875648.0\n",
            "Epoch: 616 | Loss: 6342875648.0 | Test Loss: 6342856192.0\n",
            "Epoch: 617 | Loss: 6342856192.0 | Test Loss: 6342836736.0\n",
            "Epoch: 618 | Loss: 6342836736.0 | Test Loss: 6342817280.0\n",
            "Epoch: 619 | Loss: 6342817280.0 | Test Loss: 6342797824.0\n",
            "Epoch: 620 | Loss: 6342797824.0 | Test Loss: 6342778880.0\n",
            "Epoch: 621 | Loss: 6342778880.0 | Test Loss: 6342759424.0\n",
            "Epoch: 622 | Loss: 6342759424.0 | Test Loss: 6342739456.0\n",
            "Epoch: 623 | Loss: 6342739456.0 | Test Loss: 6342721024.0\n",
            "Epoch: 624 | Loss: 6342721024.0 | Test Loss: 6342701056.0\n",
            "Epoch: 625 | Loss: 6342701056.0 | Test Loss: 6342683136.0\n",
            "Epoch: 626 | Loss: 6342683136.0 | Test Loss: 6342662656.0\n",
            "Epoch: 627 | Loss: 6342662656.0 | Test Loss: 6342643712.0\n",
            "Epoch: 628 | Loss: 6342643712.0 | Test Loss: 6342624768.0\n",
            "Epoch: 629 | Loss: 6342624768.0 | Test Loss: 6342605312.0\n",
            "Epoch: 630 | Loss: 6342605312.0 | Test Loss: 6342585856.0\n",
            "Epoch: 631 | Loss: 6342585856.0 | Test Loss: 6342566912.0\n",
            "Epoch: 632 | Loss: 6342566912.0 | Test Loss: 6342547968.0\n",
            "Epoch: 633 | Loss: 6342547968.0 | Test Loss: 6342529024.0\n",
            "Epoch: 634 | Loss: 6342529024.0 | Test Loss: 6342509568.0\n",
            "Epoch: 635 | Loss: 6342509568.0 | Test Loss: 6342491136.0\n",
            "Epoch: 636 | Loss: 6342491136.0 | Test Loss: 6342471680.0\n",
            "Epoch: 637 | Loss: 6342471680.0 | Test Loss: 6342452736.0\n",
            "Epoch: 638 | Loss: 6342452736.0 | Test Loss: 6342433792.0\n",
            "Epoch: 639 | Loss: 6342433792.0 | Test Loss: 6342414336.0\n",
            "Epoch: 640 | Loss: 6342414336.0 | Test Loss: 6342395904.0\n",
            "Epoch: 641 | Loss: 6342395904.0 | Test Loss: 6342377472.0\n",
            "Epoch: 642 | Loss: 6342377472.0 | Test Loss: 6342358528.0\n",
            "Epoch: 643 | Loss: 6342358528.0 | Test Loss: 6342339584.0\n",
            "Epoch: 644 | Loss: 6342339584.0 | Test Loss: 6342320128.0\n",
            "Epoch: 645 | Loss: 6342320128.0 | Test Loss: 6342301696.0\n",
            "Epoch: 646 | Loss: 6342301696.0 | Test Loss: 6342282752.0\n",
            "Epoch: 647 | Loss: 6342282752.0 | Test Loss: 6342263808.0\n",
            "Epoch: 648 | Loss: 6342263808.0 | Test Loss: 6342245376.0\n",
            "Epoch: 649 | Loss: 6342245376.0 | Test Loss: 6342226944.0\n",
            "Epoch: 650 | Loss: 6342226944.0 | Test Loss: 6342208000.0\n",
            "Epoch: 651 | Loss: 6342208000.0 | Test Loss: 6342189568.0\n",
            "Epoch: 652 | Loss: 6342189568.0 | Test Loss: 6342171136.0\n",
            "Epoch: 653 | Loss: 6342171136.0 | Test Loss: 6342152704.0\n",
            "Epoch: 654 | Loss: 6342152704.0 | Test Loss: 6342133760.0\n",
            "Epoch: 655 | Loss: 6342133760.0 | Test Loss: 6342114816.0\n",
            "Epoch: 656 | Loss: 6342114816.0 | Test Loss: 6342096384.0\n",
            "Epoch: 657 | Loss: 6342096384.0 | Test Loss: 6342078464.0\n",
            "Epoch: 658 | Loss: 6342078464.0 | Test Loss: 6342059520.0\n",
            "Epoch: 659 | Loss: 6342059520.0 | Test Loss: 6342040064.0\n",
            "Epoch: 660 | Loss: 6342040064.0 | Test Loss: 6342022144.0\n",
            "Epoch: 661 | Loss: 6342022144.0 | Test Loss: 6342004224.0\n",
            "Epoch: 662 | Loss: 6342004224.0 | Test Loss: 6341985792.0\n",
            "Epoch: 663 | Loss: 6341985792.0 | Test Loss: 6341967360.0\n",
            "Epoch: 664 | Loss: 6341967360.0 | Test Loss: 6341948416.0\n",
            "Epoch: 665 | Loss: 6341948416.0 | Test Loss: 6341930496.0\n",
            "Epoch: 666 | Loss: 6341930496.0 | Test Loss: 6341912576.0\n",
            "Epoch: 667 | Loss: 6341912576.0 | Test Loss: 6341893632.0\n",
            "Epoch: 668 | Loss: 6341893632.0 | Test Loss: 6341875200.0\n",
            "Epoch: 669 | Loss: 6341875200.0 | Test Loss: 6341857280.0\n",
            "Epoch: 670 | Loss: 6341857280.0 | Test Loss: 6341838848.0\n",
            "Epoch: 671 | Loss: 6341838848.0 | Test Loss: 6341820416.0\n",
            "Epoch: 672 | Loss: 6341820416.0 | Test Loss: 6341802496.0\n",
            "Epoch: 673 | Loss: 6341802496.0 | Test Loss: 6341784576.0\n",
            "Epoch: 674 | Loss: 6341784576.0 | Test Loss: 6341766144.0\n",
            "Epoch: 675 | Loss: 6341766144.0 | Test Loss: 6341748224.0\n",
            "Epoch: 676 | Loss: 6341748224.0 | Test Loss: 6341729792.0\n",
            "Epoch: 677 | Loss: 6341729792.0 | Test Loss: 6341712384.0\n",
            "Epoch: 678 | Loss: 6341712384.0 | Test Loss: 6341693952.0\n",
            "Epoch: 679 | Loss: 6341693952.0 | Test Loss: 6341675520.0\n",
            "Epoch: 680 | Loss: 6341675520.0 | Test Loss: 6341658624.0\n",
            "Epoch: 681 | Loss: 6341658624.0 | Test Loss: 6341639680.0\n",
            "Epoch: 682 | Loss: 6341639680.0 | Test Loss: 6341622272.0\n",
            "Epoch: 683 | Loss: 6341622272.0 | Test Loss: 6341603840.0\n",
            "Epoch: 684 | Loss: 6341603840.0 | Test Loss: 6341585920.0\n",
            "Epoch: 685 | Loss: 6341585920.0 | Test Loss: 6341569024.0\n",
            "Epoch: 686 | Loss: 6341569024.0 | Test Loss: 6341550592.0\n",
            "Epoch: 687 | Loss: 6341550592.0 | Test Loss: 6341533184.0\n",
            "Epoch: 688 | Loss: 6341533184.0 | Test Loss: 6341514240.0\n",
            "Epoch: 689 | Loss: 6341514240.0 | Test Loss: 6341496320.0\n",
            "Epoch: 690 | Loss: 6341496320.0 | Test Loss: 6341478912.0\n",
            "Epoch: 691 | Loss: 6341478912.0 | Test Loss: 6341461504.0\n",
            "Epoch: 692 | Loss: 6341461504.0 | Test Loss: 6341444096.0\n",
            "Epoch: 693 | Loss: 6341444096.0 | Test Loss: 6341425152.0\n",
            "Epoch: 694 | Loss: 6341425152.0 | Test Loss: 6341408256.0\n",
            "Epoch: 695 | Loss: 6341408256.0 | Test Loss: 6341389824.0\n",
            "Epoch: 696 | Loss: 6341389824.0 | Test Loss: 6341372928.0\n",
            "Epoch: 697 | Loss: 6341372928.0 | Test Loss: 6341354496.0\n",
            "Epoch: 698 | Loss: 6341354496.0 | Test Loss: 6341337600.0\n",
            "Epoch: 699 | Loss: 6341337600.0 | Test Loss: 6341320192.0\n",
            "Epoch: 700 | Loss: 6341320192.0 | Test Loss: 6341301760.0\n",
            "Epoch: 701 | Loss: 6341301760.0 | Test Loss: 6341284864.0\n",
            "Epoch: 702 | Loss: 6341284864.0 | Test Loss: 6341267456.0\n",
            "Epoch: 703 | Loss: 6341267456.0 | Test Loss: 6341250048.0\n",
            "Epoch: 704 | Loss: 6341250048.0 | Test Loss: 6341231616.0\n",
            "Epoch: 705 | Loss: 6341231616.0 | Test Loss: 6341214720.0\n",
            "Epoch: 706 | Loss: 6341214720.0 | Test Loss: 6341196800.0\n",
            "Epoch: 707 | Loss: 6341196800.0 | Test Loss: 6341179904.0\n",
            "Epoch: 708 | Loss: 6341179904.0 | Test Loss: 6341161984.0\n",
            "Epoch: 709 | Loss: 6341161984.0 | Test Loss: 6341144576.0\n",
            "Epoch: 710 | Loss: 6341144576.0 | Test Loss: 6341128192.0\n",
            "Epoch: 711 | Loss: 6341128192.0 | Test Loss: 6341110272.0\n",
            "Epoch: 712 | Loss: 6341110272.0 | Test Loss: 6341092352.0\n",
            "Epoch: 713 | Loss: 6341092352.0 | Test Loss: 6341074432.0\n",
            "Epoch: 714 | Loss: 6341074432.0 | Test Loss: 6341058048.0\n",
            "Epoch: 715 | Loss: 6341058048.0 | Test Loss: 6341040640.0\n",
            "Epoch: 716 | Loss: 6341040640.0 | Test Loss: 6341023744.0\n",
            "Epoch: 717 | Loss: 6341023744.0 | Test Loss: 6341006848.0\n",
            "Epoch: 718 | Loss: 6341006848.0 | Test Loss: 6340988928.0\n",
            "Epoch: 719 | Loss: 6340988928.0 | Test Loss: 6340972544.0\n",
            "Epoch: 720 | Loss: 6340972544.0 | Test Loss: 6340955136.0\n",
            "Epoch: 721 | Loss: 6340955136.0 | Test Loss: 6340938240.0\n",
            "Epoch: 722 | Loss: 6340938240.0 | Test Loss: 6340920832.0\n",
            "Epoch: 723 | Loss: 6340920832.0 | Test Loss: 6340903936.0\n",
            "Epoch: 724 | Loss: 6340903936.0 | Test Loss: 6340886016.0\n",
            "Epoch: 725 | Loss: 6340886016.0 | Test Loss: 6340869632.0\n",
            "Epoch: 726 | Loss: 6340869632.0 | Test Loss: 6340851712.0\n",
            "Epoch: 727 | Loss: 6340851712.0 | Test Loss: 6340835840.0\n",
            "Epoch: 728 | Loss: 6340835840.0 | Test Loss: 6340819456.0\n",
            "Epoch: 729 | Loss: 6340819456.0 | Test Loss: 6340801536.0\n",
            "Epoch: 730 | Loss: 6340801536.0 | Test Loss: 6340785152.0\n",
            "Epoch: 731 | Loss: 6340785152.0 | Test Loss: 6340767744.0\n",
            "Epoch: 732 | Loss: 6340767744.0 | Test Loss: 6340750848.0\n",
            "Epoch: 733 | Loss: 6340750848.0 | Test Loss: 6340733952.0\n",
            "Epoch: 734 | Loss: 6340733952.0 | Test Loss: 6340717056.0\n",
            "Epoch: 735 | Loss: 6340717056.0 | Test Loss: 6340699648.0\n",
            "Epoch: 736 | Loss: 6340699648.0 | Test Loss: 6340683264.0\n",
            "Epoch: 737 | Loss: 6340683264.0 | Test Loss: 6340665856.0\n",
            "Epoch: 738 | Loss: 6340665856.0 | Test Loss: 6340649472.0\n",
            "Epoch: 739 | Loss: 6340649472.0 | Test Loss: 6340633088.0\n",
            "Epoch: 740 | Loss: 6340633088.0 | Test Loss: 6340616704.0\n",
            "Epoch: 741 | Loss: 6340616704.0 | Test Loss: 6340599296.0\n",
            "Epoch: 742 | Loss: 6340599296.0 | Test Loss: 6340582912.0\n",
            "Epoch: 743 | Loss: 6340582912.0 | Test Loss: 6340566016.0\n",
            "Epoch: 744 | Loss: 6340566016.0 | Test Loss: 6340549120.0\n",
            "Epoch: 745 | Loss: 6340549120.0 | Test Loss: 6340532224.0\n",
            "Epoch: 746 | Loss: 6340532224.0 | Test Loss: 6340515840.0\n",
            "Epoch: 747 | Loss: 6340515840.0 | Test Loss: 6340499456.0\n",
            "Epoch: 748 | Loss: 6340499456.0 | Test Loss: 6340482560.0\n",
            "Epoch: 749 | Loss: 6340482560.0 | Test Loss: 6340466176.0\n",
            "Epoch: 750 | Loss: 6340466176.0 | Test Loss: 6340449280.0\n",
            "Epoch: 751 | Loss: 6340449280.0 | Test Loss: 6340433408.0\n",
            "Epoch: 752 | Loss: 6340433408.0 | Test Loss: 6340416000.0\n",
            "Epoch: 753 | Loss: 6340416000.0 | Test Loss: 6340400128.0\n",
            "Epoch: 754 | Loss: 6340400128.0 | Test Loss: 6340384256.0\n",
            "Epoch: 755 | Loss: 6340384256.0 | Test Loss: 6340366848.0\n",
            "Epoch: 756 | Loss: 6340366848.0 | Test Loss: 6340350976.0\n",
            "Epoch: 757 | Loss: 6340350976.0 | Test Loss: 6340334080.0\n",
            "Epoch: 758 | Loss: 6340334080.0 | Test Loss: 6340318208.0\n",
            "Epoch: 759 | Loss: 6340318208.0 | Test Loss: 6340301312.0\n",
            "Epoch: 760 | Loss: 6340301312.0 | Test Loss: 6340284928.0\n",
            "Epoch: 761 | Loss: 6340284928.0 | Test Loss: 6340268032.0\n",
            "Epoch: 762 | Loss: 6340268032.0 | Test Loss: 6340252672.0\n",
            "Epoch: 763 | Loss: 6340252672.0 | Test Loss: 6340236288.0\n",
            "Epoch: 764 | Loss: 6340236288.0 | Test Loss: 6340220416.0\n",
            "Epoch: 765 | Loss: 6340220416.0 | Test Loss: 6340203520.0\n",
            "Epoch: 766 | Loss: 6340203520.0 | Test Loss: 6340187648.0\n",
            "Epoch: 767 | Loss: 6340187648.0 | Test Loss: 6340170752.0\n",
            "Epoch: 768 | Loss: 6340170752.0 | Test Loss: 6340154880.0\n",
            "Epoch: 769 | Loss: 6340154880.0 | Test Loss: 6340138496.0\n",
            "Epoch: 770 | Loss: 6340138496.0 | Test Loss: 6340122624.0\n",
            "Epoch: 771 | Loss: 6340122624.0 | Test Loss: 6340106240.0\n",
            "Epoch: 772 | Loss: 6340106240.0 | Test Loss: 6340090368.0\n",
            "Epoch: 773 | Loss: 6340090368.0 | Test Loss: 6340074496.0\n",
            "Epoch: 774 | Loss: 6340074496.0 | Test Loss: 6340058624.0\n",
            "Epoch: 775 | Loss: 6340058624.0 | Test Loss: 6340042240.0\n",
            "Epoch: 776 | Loss: 6340042240.0 | Test Loss: 6340025856.0\n",
            "Epoch: 777 | Loss: 6340025856.0 | Test Loss: 6340009984.0\n",
            "Epoch: 778 | Loss: 6340009984.0 | Test Loss: 6339994112.0\n",
            "Epoch: 779 | Loss: 6339994112.0 | Test Loss: 6339977728.0\n",
            "Epoch: 780 | Loss: 6339977728.0 | Test Loss: 6339962880.0\n",
            "Epoch: 781 | Loss: 6339962880.0 | Test Loss: 6339946496.0\n",
            "Epoch: 782 | Loss: 6339946496.0 | Test Loss: 6339929600.0\n",
            "Epoch: 783 | Loss: 6339929600.0 | Test Loss: 6339913728.0\n",
            "Epoch: 784 | Loss: 6339913728.0 | Test Loss: 6339897856.0\n",
            "Epoch: 785 | Loss: 6339897856.0 | Test Loss: 6339882496.0\n",
            "Epoch: 786 | Loss: 6339882496.0 | Test Loss: 6339866624.0\n",
            "Epoch: 787 | Loss: 6339866624.0 | Test Loss: 6339850752.0\n",
            "Epoch: 788 | Loss: 6339850752.0 | Test Loss: 6339834880.0\n",
            "Epoch: 789 | Loss: 6339834880.0 | Test Loss: 6339819008.0\n",
            "Epoch: 790 | Loss: 6339819008.0 | Test Loss: 6339803136.0\n",
            "Epoch: 791 | Loss: 6339803136.0 | Test Loss: 6339788288.0\n",
            "Epoch: 792 | Loss: 6339788288.0 | Test Loss: 6339771392.0\n",
            "Epoch: 793 | Loss: 6339771392.0 | Test Loss: 6339756032.0\n",
            "Epoch: 794 | Loss: 6339756032.0 | Test Loss: 6339739648.0\n",
            "Epoch: 795 | Loss: 6339739648.0 | Test Loss: 6339725312.0\n",
            "Epoch: 796 | Loss: 6339725312.0 | Test Loss: 6339708928.0\n",
            "Epoch: 797 | Loss: 6339708928.0 | Test Loss: 6339693568.0\n",
            "Epoch: 798 | Loss: 6339693568.0 | Test Loss: 6339677696.0\n",
            "Epoch: 799 | Loss: 6339677696.0 | Test Loss: 6339661824.0\n",
            "Epoch: 800 | Loss: 6339661824.0 | Test Loss: 6339646976.0\n",
            "Epoch: 801 | Loss: 6339646976.0 | Test Loss: 6339631616.0\n",
            "Epoch: 802 | Loss: 6339631616.0 | Test Loss: 6339614720.0\n",
            "Epoch: 803 | Loss: 6339614720.0 | Test Loss: 6339599360.0\n",
            "Epoch: 804 | Loss: 6339599360.0 | Test Loss: 6339584000.0\n",
            "Epoch: 805 | Loss: 6339584000.0 | Test Loss: 6339568640.0\n",
            "Epoch: 806 | Loss: 6339568640.0 | Test Loss: 6339553280.0\n",
            "Epoch: 807 | Loss: 6339553280.0 | Test Loss: 6339537920.0\n",
            "Epoch: 808 | Loss: 6339537920.0 | Test Loss: 6339521536.0\n",
            "Epoch: 809 | Loss: 6339521536.0 | Test Loss: 6339507200.0\n",
            "Epoch: 810 | Loss: 6339507200.0 | Test Loss: 6339490816.0\n",
            "Epoch: 811 | Loss: 6339490816.0 | Test Loss: 6339475968.0\n",
            "Epoch: 812 | Loss: 6339475968.0 | Test Loss: 6339460096.0\n",
            "Epoch: 813 | Loss: 6339460096.0 | Test Loss: 6339444736.0\n",
            "Epoch: 814 | Loss: 6339444736.0 | Test Loss: 6339429888.0\n",
            "Epoch: 815 | Loss: 6339429888.0 | Test Loss: 6339414528.0\n",
            "Epoch: 816 | Loss: 6339414528.0 | Test Loss: 6339398144.0\n",
            "Epoch: 817 | Loss: 6339398144.0 | Test Loss: 6339383808.0\n",
            "Epoch: 818 | Loss: 6339383808.0 | Test Loss: 6339367936.0\n",
            "Epoch: 819 | Loss: 6339367936.0 | Test Loss: 6339353088.0\n",
            "Epoch: 820 | Loss: 6339353088.0 | Test Loss: 6339337216.0\n",
            "Epoch: 821 | Loss: 6339337216.0 | Test Loss: 6339322368.0\n",
            "Epoch: 822 | Loss: 6339322368.0 | Test Loss: 6339307520.0\n",
            "Epoch: 823 | Loss: 6339307520.0 | Test Loss: 6339293184.0\n",
            "Epoch: 824 | Loss: 6339293184.0 | Test Loss: 6339276800.0\n",
            "Epoch: 825 | Loss: 6339276800.0 | Test Loss: 6339261952.0\n",
            "Epoch: 826 | Loss: 6339261952.0 | Test Loss: 6339247104.0\n",
            "Epoch: 827 | Loss: 6339247104.0 | Test Loss: 6339231744.0\n",
            "Epoch: 828 | Loss: 6339231744.0 | Test Loss: 6339216384.0\n",
            "Epoch: 829 | Loss: 6339216384.0 | Test Loss: 6339201024.0\n",
            "Epoch: 830 | Loss: 6339201024.0 | Test Loss: 6339187200.0\n",
            "Epoch: 831 | Loss: 6339187200.0 | Test Loss: 6339171328.0\n",
            "Epoch: 832 | Loss: 6339171328.0 | Test Loss: 6339156480.0\n",
            "Epoch: 833 | Loss: 6339156480.0 | Test Loss: 6339141120.0\n",
            "Epoch: 834 | Loss: 6339141120.0 | Test Loss: 6339126272.0\n",
            "Epoch: 835 | Loss: 6339126272.0 | Test Loss: 6339110912.0\n",
            "Epoch: 836 | Loss: 6339110912.0 | Test Loss: 6339096064.0\n",
            "Epoch: 837 | Loss: 6339096064.0 | Test Loss: 6339081216.0\n",
            "Epoch: 838 | Loss: 6339081216.0 | Test Loss: 6339066880.0\n",
            "Epoch: 839 | Loss: 6339066880.0 | Test Loss: 6339051520.0\n",
            "Epoch: 840 | Loss: 6339051520.0 | Test Loss: 6339036672.0\n",
            "Epoch: 841 | Loss: 6339036672.0 | Test Loss: 6339021312.0\n",
            "Epoch: 842 | Loss: 6339021312.0 | Test Loss: 6339006976.0\n",
            "Epoch: 843 | Loss: 6339006976.0 | Test Loss: 6338992128.0\n",
            "Epoch: 844 | Loss: 6338992128.0 | Test Loss: 6338977792.0\n",
            "Epoch: 845 | Loss: 6338977792.0 | Test Loss: 6338962432.0\n",
            "Epoch: 846 | Loss: 6338962432.0 | Test Loss: 6338947584.0\n",
            "Epoch: 847 | Loss: 6338947584.0 | Test Loss: 6338932736.0\n",
            "Epoch: 848 | Loss: 6338932736.0 | Test Loss: 6338918400.0\n",
            "Epoch: 849 | Loss: 6338918400.0 | Test Loss: 6338903040.0\n",
            "Epoch: 850 | Loss: 6338903040.0 | Test Loss: 6338888704.0\n",
            "Epoch: 851 | Loss: 6338888704.0 | Test Loss: 6338873344.0\n",
            "Epoch: 852 | Loss: 6338873344.0 | Test Loss: 6338858496.0\n",
            "Epoch: 853 | Loss: 6338858496.0 | Test Loss: 6338844672.0\n",
            "Epoch: 854 | Loss: 6338844672.0 | Test Loss: 6338829312.0\n",
            "Epoch: 855 | Loss: 6338829312.0 | Test Loss: 6338815488.0\n",
            "Epoch: 856 | Loss: 6338815488.0 | Test Loss: 6338800640.0\n",
            "Epoch: 857 | Loss: 6338800640.0 | Test Loss: 6338785280.0\n",
            "Epoch: 858 | Loss: 6338785280.0 | Test Loss: 6338770944.0\n",
            "Epoch: 859 | Loss: 6338770944.0 | Test Loss: 6338757120.0\n",
            "Epoch: 860 | Loss: 6338757120.0 | Test Loss: 6338741760.0\n",
            "Epoch: 861 | Loss: 6338741760.0 | Test Loss: 6338727936.0\n",
            "Epoch: 862 | Loss: 6338727936.0 | Test Loss: 6338713088.0\n",
            "Epoch: 863 | Loss: 6338713088.0 | Test Loss: 6338698752.0\n",
            "Epoch: 864 | Loss: 6338698752.0 | Test Loss: 6338684416.0\n",
            "Epoch: 865 | Loss: 6338684416.0 | Test Loss: 6338670080.0\n",
            "Epoch: 866 | Loss: 6338670080.0 | Test Loss: 6338655232.0\n",
            "Epoch: 867 | Loss: 6338655232.0 | Test Loss: 6338640384.0\n",
            "Epoch: 868 | Loss: 6338640384.0 | Test Loss: 6338626560.0\n",
            "Epoch: 869 | Loss: 6338626560.0 | Test Loss: 6338611712.0\n",
            "Epoch: 870 | Loss: 6338611712.0 | Test Loss: 6338597888.0\n",
            "Epoch: 871 | Loss: 6338597888.0 | Test Loss: 6338583552.0\n",
            "Epoch: 872 | Loss: 6338583552.0 | Test Loss: 6338569216.0\n",
            "Epoch: 873 | Loss: 6338569216.0 | Test Loss: 6338554880.0\n",
            "Epoch: 874 | Loss: 6338554880.0 | Test Loss: 6338540544.0\n",
            "Epoch: 875 | Loss: 6338540544.0 | Test Loss: 6338526208.0\n",
            "Epoch: 876 | Loss: 6338526208.0 | Test Loss: 6338511872.0\n",
            "Epoch: 877 | Loss: 6338511872.0 | Test Loss: 6338498048.0\n",
            "Epoch: 878 | Loss: 6338498048.0 | Test Loss: 6338483712.0\n",
            "Epoch: 879 | Loss: 6338483712.0 | Test Loss: 6338468864.0\n",
            "Epoch: 880 | Loss: 6338468864.0 | Test Loss: 6338454528.0\n",
            "Epoch: 881 | Loss: 6338454528.0 | Test Loss: 6338441216.0\n",
            "Epoch: 882 | Loss: 6338441216.0 | Test Loss: 6338426368.0\n",
            "Epoch: 883 | Loss: 6338426368.0 | Test Loss: 6338412544.0\n",
            "Epoch: 884 | Loss: 6338412544.0 | Test Loss: 6338398208.0\n",
            "Epoch: 885 | Loss: 6338398208.0 | Test Loss: 6338383872.0\n",
            "Epoch: 886 | Loss: 6338383872.0 | Test Loss: 6338370048.0\n",
            "Epoch: 887 | Loss: 6338370048.0 | Test Loss: 6338355712.0\n",
            "Epoch: 888 | Loss: 6338355712.0 | Test Loss: 6338341888.0\n",
            "Epoch: 889 | Loss: 6338341888.0 | Test Loss: 6338327552.0\n",
            "Epoch: 890 | Loss: 6338327552.0 | Test Loss: 6338313728.0\n",
            "Epoch: 891 | Loss: 6338313728.0 | Test Loss: 6338299392.0\n",
            "Epoch: 892 | Loss: 6338299392.0 | Test Loss: 6338286592.0\n",
            "Epoch: 893 | Loss: 6338286592.0 | Test Loss: 6338271232.0\n",
            "Epoch: 894 | Loss: 6338271232.0 | Test Loss: 6338257920.0\n",
            "Epoch: 895 | Loss: 6338257920.0 | Test Loss: 6338243584.0\n",
            "Epoch: 896 | Loss: 6338243584.0 | Test Loss: 6338230272.0\n",
            "Epoch: 897 | Loss: 6338230272.0 | Test Loss: 6338215424.0\n",
            "Epoch: 898 | Loss: 6338215424.0 | Test Loss: 6338202112.0\n",
            "Epoch: 899 | Loss: 6338202112.0 | Test Loss: 6338188288.0\n",
            "Epoch: 900 | Loss: 6338188288.0 | Test Loss: 6338173440.0\n",
            "Epoch: 901 | Loss: 6338173440.0 | Test Loss: 6338160128.0\n",
            "Epoch: 902 | Loss: 6338160128.0 | Test Loss: 6338145792.0\n",
            "Epoch: 903 | Loss: 6338145792.0 | Test Loss: 6338132480.0\n",
            "Epoch: 904 | Loss: 6338132480.0 | Test Loss: 6338118656.0\n",
            "Epoch: 905 | Loss: 6338118656.0 | Test Loss: 6338104320.0\n",
            "Epoch: 906 | Loss: 6338104320.0 | Test Loss: 6338091520.0\n",
            "Epoch: 907 | Loss: 6338091520.0 | Test Loss: 6338077184.0\n",
            "Epoch: 908 | Loss: 6338077184.0 | Test Loss: 6338063872.0\n",
            "Epoch: 909 | Loss: 6338063872.0 | Test Loss: 6338049536.0\n",
            "Epoch: 910 | Loss: 6338049536.0 | Test Loss: 6338036224.0\n",
            "Epoch: 911 | Loss: 6338036224.0 | Test Loss: 6338021888.0\n",
            "Epoch: 912 | Loss: 6338021888.0 | Test Loss: 6338009088.0\n",
            "Epoch: 913 | Loss: 6338009088.0 | Test Loss: 6337994752.0\n",
            "Epoch: 914 | Loss: 6337994752.0 | Test Loss: 6337980928.0\n",
            "Epoch: 915 | Loss: 6337980928.0 | Test Loss: 6337967104.0\n",
            "Epoch: 916 | Loss: 6337967104.0 | Test Loss: 6337953792.0\n",
            "Epoch: 917 | Loss: 6337953792.0 | Test Loss: 6337939968.0\n",
            "Epoch: 918 | Loss: 6337939968.0 | Test Loss: 6337927168.0\n",
            "Epoch: 919 | Loss: 6337927168.0 | Test Loss: 6337912832.0\n",
            "Epoch: 920 | Loss: 6337912832.0 | Test Loss: 6337899520.0\n",
            "Epoch: 921 | Loss: 6337899520.0 | Test Loss: 6337885696.0\n",
            "Epoch: 922 | Loss: 6337885696.0 | Test Loss: 6337872896.0\n",
            "Epoch: 923 | Loss: 6337872896.0 | Test Loss: 6337859072.0\n",
            "Epoch: 924 | Loss: 6337859072.0 | Test Loss: 6337845760.0\n",
            "Epoch: 925 | Loss: 6337845760.0 | Test Loss: 6337831424.0\n",
            "Epoch: 926 | Loss: 6337831424.0 | Test Loss: 6337818624.0\n",
            "Epoch: 927 | Loss: 6337818624.0 | Test Loss: 6337804288.0\n",
            "Epoch: 928 | Loss: 6337804288.0 | Test Loss: 6337791488.0\n",
            "Epoch: 929 | Loss: 6337791488.0 | Test Loss: 6337778688.0\n",
            "Epoch: 930 | Loss: 6337778688.0 | Test Loss: 6337764864.0\n",
            "Epoch: 931 | Loss: 6337764864.0 | Test Loss: 6337751552.0\n",
            "Epoch: 932 | Loss: 6337751552.0 | Test Loss: 6337737216.0\n",
            "Epoch: 933 | Loss: 6337737216.0 | Test Loss: 6337724416.0\n",
            "Epoch: 934 | Loss: 6337724416.0 | Test Loss: 6337710592.0\n",
            "Epoch: 935 | Loss: 6337710592.0 | Test Loss: 6337698304.0\n",
            "Epoch: 936 | Loss: 6337698304.0 | Test Loss: 6337684480.0\n",
            "Epoch: 937 | Loss: 6337684480.0 | Test Loss: 6337671680.0\n",
            "Epoch: 938 | Loss: 6337671680.0 | Test Loss: 6337657856.0\n",
            "Epoch: 939 | Loss: 6337657856.0 | Test Loss: 6337644544.0\n",
            "Epoch: 940 | Loss: 6337644544.0 | Test Loss: 6337631232.0\n",
            "Epoch: 941 | Loss: 6337631232.0 | Test Loss: 6337616896.0\n",
            "Epoch: 942 | Loss: 6337616896.0 | Test Loss: 6337605120.0\n",
            "Epoch: 943 | Loss: 6337605120.0 | Test Loss: 6337590784.0\n",
            "Epoch: 944 | Loss: 6337590784.0 | Test Loss: 6337578496.0\n",
            "Epoch: 945 | Loss: 6337578496.0 | Test Loss: 6337565696.0\n",
            "Epoch: 946 | Loss: 6337565696.0 | Test Loss: 6337551360.0\n",
            "Epoch: 947 | Loss: 6337551360.0 | Test Loss: 6337539072.0\n",
            "Epoch: 948 | Loss: 6337539072.0 | Test Loss: 6337525760.0\n",
            "Epoch: 949 | Loss: 6337525760.0 | Test Loss: 6337512960.0\n",
            "Epoch: 950 | Loss: 6337512960.0 | Test Loss: 6337499136.0\n",
            "Epoch: 951 | Loss: 6337499136.0 | Test Loss: 6337486336.0\n",
            "Epoch: 952 | Loss: 6337486336.0 | Test Loss: 6337473024.0\n",
            "Epoch: 953 | Loss: 6337473024.0 | Test Loss: 6337459712.0\n",
            "Epoch: 954 | Loss: 6337459712.0 | Test Loss: 6337446400.0\n",
            "Epoch: 955 | Loss: 6337446400.0 | Test Loss: 6337433600.0\n",
            "Epoch: 956 | Loss: 6337433600.0 | Test Loss: 6337420288.0\n",
            "Epoch: 957 | Loss: 6337420288.0 | Test Loss: 6337407488.0\n",
            "Epoch: 958 | Loss: 6337407488.0 | Test Loss: 6337394176.0\n",
            "Epoch: 959 | Loss: 6337394176.0 | Test Loss: 6337381888.0\n",
            "Epoch: 960 | Loss: 6337381888.0 | Test Loss: 6337368576.0\n",
            "Epoch: 961 | Loss: 6337368576.0 | Test Loss: 6337355776.0\n",
            "Epoch: 962 | Loss: 6337355776.0 | Test Loss: 6337342464.0\n",
            "Epoch: 963 | Loss: 6337342464.0 | Test Loss: 6337330176.0\n",
            "Epoch: 964 | Loss: 6337330176.0 | Test Loss: 6337316864.0\n",
            "Epoch: 965 | Loss: 6337316864.0 | Test Loss: 6337303552.0\n",
            "Epoch: 966 | Loss: 6337303552.0 | Test Loss: 6337290752.0\n",
            "Epoch: 967 | Loss: 6337290752.0 | Test Loss: 6337277952.0\n",
            "Epoch: 968 | Loss: 6337277952.0 | Test Loss: 6337265152.0\n",
            "Epoch: 969 | Loss: 6337265152.0 | Test Loss: 6337252352.0\n",
            "Epoch: 970 | Loss: 6337252352.0 | Test Loss: 6337239552.0\n",
            "Epoch: 971 | Loss: 6337239552.0 | Test Loss: 6337226752.0\n",
            "Epoch: 972 | Loss: 6337226752.0 | Test Loss: 6337213440.0\n",
            "Epoch: 973 | Loss: 6337213440.0 | Test Loss: 6337201152.0\n",
            "Epoch: 974 | Loss: 6337201152.0 | Test Loss: 6337188352.0\n",
            "Epoch: 975 | Loss: 6337188352.0 | Test Loss: 6337175040.0\n",
            "Epoch: 976 | Loss: 6337175040.0 | Test Loss: 6337162752.0\n",
            "Epoch: 977 | Loss: 6337162752.0 | Test Loss: 6337149952.0\n",
            "Epoch: 978 | Loss: 6337149952.0 | Test Loss: 6337137152.0\n",
            "Epoch: 979 | Loss: 6337137152.0 | Test Loss: 6337124352.0\n",
            "Epoch: 980 | Loss: 6337124352.0 | Test Loss: 6337111552.0\n",
            "Epoch: 981 | Loss: 6337111552.0 | Test Loss: 6337099264.0\n",
            "Epoch: 982 | Loss: 6337099264.0 | Test Loss: 6337086464.0\n",
            "Epoch: 983 | Loss: 6337086464.0 | Test Loss: 6337073664.0\n",
            "Epoch: 984 | Loss: 6337073664.0 | Test Loss: 6337060864.0\n",
            "Epoch: 985 | Loss: 6337060864.0 | Test Loss: 6337048576.0\n",
            "Epoch: 986 | Loss: 6337048576.0 | Test Loss: 6337035264.0\n",
            "Epoch: 987 | Loss: 6337035264.0 | Test Loss: 6337022976.0\n",
            "Epoch: 988 | Loss: 6337022976.0 | Test Loss: 6337010176.0\n",
            "Epoch: 989 | Loss: 6337010176.0 | Test Loss: 6336997888.0\n",
            "Epoch: 990 | Loss: 6336997888.0 | Test Loss: 6336985088.0\n",
            "Epoch: 991 | Loss: 6336985088.0 | Test Loss: 6336972800.0\n",
            "Epoch: 992 | Loss: 6336972800.0 | Test Loss: 6336960512.0\n",
            "Epoch: 993 | Loss: 6336960512.0 | Test Loss: 6336947712.0\n",
            "Epoch: 994 | Loss: 6336947712.0 | Test Loss: 6336934912.0\n",
            "Epoch: 995 | Loss: 6336934912.0 | Test Loss: 6336923136.0\n",
            "Epoch: 996 | Loss: 6336923136.0 | Test Loss: 6336909824.0\n",
            "Epoch: 997 | Loss: 6336909824.0 | Test Loss: 6336897536.0\n",
            "Epoch: 998 | Loss: 6336897536.0 | Test Loss: 6336885760.0\n",
            "Epoch: 999 | Loss: 6336885760.0 | Test Loss: 6336871936.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' evaluate the model '''\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    y_pred = model(labels.float())\n",
        "    loss = loss_fun(y_pred,target.float())\n",
        "    print(f\"Loss: {loss}\")\n",
        "''' compare the real value with the predicted one  '''\n",
        "target[:5],y_pred[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEb90QY_o7NK",
        "outputId": "cec89b6b-a73e-41d4-f67c-1d470caf5024"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 6336871936.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([208500., 181500., 223500., 140000., 250000.]),\n",
              " tensor([[185903.6719],\n",
              "         [180518.8906],\n",
              "         [179615.2031],\n",
              "         [176826.2812],\n",
              "         [179946.4531]]))"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nw9WIeVkpYEY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}